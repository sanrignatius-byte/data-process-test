{
  "meta": {
    "input": "data/l1_triage_v3.jsonl",
    "total_rows": 727,
    "topk": 100,
    "min_class": "A",
    "num_pairs": 43,
    "total_docs": 72,
    "dropped_common_entities": 0,
    "max_doc_count": 25
  },
  "pairs": [
    {
      "doc_a": "1809.02244",
      "doc_b": "1907.06430",
      "shared_entity_count": 2,
      "shared_entities": [
        "compas",
        "pse"
      ],
      "doc_a_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_a_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_a_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_a_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_a_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_a_figure_id": "1809.02244_fig_4",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_a_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_1907.06430_1907.06430_fig_11_860",
      "doc_b_query": "Does the red solid arrow from A to Y represent the direct path whose unfairness is quantified by path-specific effect?",
      "doc_b_answer": "Yes, the red solid arrow from A to Y represents the direct path A → Y, whose unfairness is quantified by the path-specific effect PSE^aa when the path A → D → Y is considered fair.",
      "doc_b_visual_anchor": "red solid arrow from node A to node Y",
      "doc_b_text_evidence": "in which the path $A $ $D  Y$ is considered fair, unfairness can instead be quantified with the path-specific effect along the direct path $A  Y$ , PSE $^ { a a }$",
      "doc_b_figure_id": "1907.06430_fig_11",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1907.06430/1907.06430/hybrid_auto/images/1907.06430_page0_fig10.jpg",
      "doc_b_caption": "Fig. 7. CBN underlying a college admission scenario.",
      "doc_b_visual_score": 4,
      "score": 12.0
    },
    {
      "doc_a": "1511.00830",
      "doc_b": "1805.09458",
      "shared_entity_count": 3,
      "shared_entities": [
        "accuracy",
        "sne",
        "vfae"
      ],
      "doc_a_query_id": "l1_1511.00830_1511.00830_fig_13_73",
      "doc_a_query": "Why do the blue and red points heavily overlap in this visualization, given the model uses both s and MMD?",
      "doc_a_answer": "The model successfully factors out domain (gender) information by incorporating both the sensitive attribute s and MMD regularization, resulting in representations where male and female samples are not separable and cluster together, demonstrating fairness through indistinguishability.",
      "doc_a_visual_anchor": "overlapping blue (male) and red (female) scattered point clusters",
      "doc_a_text_evidence": "Our model was successful in factoring out the domain information, since the accuracy, measured both linearly (LR) and non-linearly (RF), was towards random chance",
      "doc_a_figure_id": "1511.00830_fig_13",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig12.jpg",
      "doc_a_caption": "Figure 4: t-SNE (van der Maaten, 2013) visualizations from the Adult dataset on: (a): original x , (b): latent $\\mathbf { z } _ { 1 }$ without s and MMD, (c): latent $\\mathbf { z } _ { 1 }$ with s and without MMD, (d): latent $\\mathbf { z } _ { 1 }$ with s and MMD. Blue colour corresponds to males whereas red colour corresponds to females.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1805.09458_1805.09458_fig_1_439",
      "doc_b_query": "Does the VFAE salmon bar at 0.75 adversarial loss indicate the encoder-decoder pair uses Gaussian reparameterization?",
      "doc_b_answer": "Yes, VFAE's modified loss (Eq. 18) requires learning an encoder-decoder pair q(z|x) and p(x|z,c) where the encoder q(z|x) uses the Gaussian reparameterization trick, as shown by the 0-layer result.",
      "doc_b_visual_anchor": "VFAE group salmon/red bar at approximately 0.75 adversarial loss",
      "doc_b_text_evidence": "We have two modified VAE loss (Eq. 18) and modified VIB loss (Eq. 31). In both we have to learn an encoder and decoder pair $q ( z | x )$ and $p ( x | z , c )$ . We use feed forward networks to approximate these functions. For $q ( z | x )$ we use the Gaussian reparameterization trick",
      "doc_b_figure_id": "1805.09458_fig_1",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: On the left we display the adversarial loss (the accuracy of the adversary on $c$ ) and predictive accurracy on $y$ for three methods, plus the majority-class baseline, on both Adult and German datasets. For adv. loss lower is better, while for pred. acc. higher is better. On the right we plot adversarial loss by varying adversarial strength (indicated by color), parameterized by the number of layers from zero (logistic regression) to three. All evaluations are performed on the hold-out test sets.",
      "doc_b_visual_score": 2,
      "score": 9.5
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "2005.07293",
      "shared_entity_count": 2,
      "shared_entities": [
        "com-pas",
        "compas"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_2005.07293_2005.07293_fig_3_909",
      "doc_b_query": "Do the near-flat red and green lines at 84% across all beta values support consistent performance across random splits?",
      "doc_b_answer": "Yes, the flat Parity and Classifier lines demonstrate consistent performance. Each point represents the average value of 10 experiments performed on the same 10 random splits across different beta values, ensuring robustness.",
      "doc_b_visual_anchor": "Red line with X markers and green line with triangle markers both maintaining approximately 84-85% accuracy from beta=0 to beta=0.9",
      "doc_b_text_evidence": "Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different beta values.",
      "doc_b_figure_id": "2005.07293_fig_3",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig2.jpg",
      "doc_b_caption": "Figure 2: Accuracy and fairness gain results for the COMPAS and Adult datasets over different $\\beta$ values. Top plots report the accuracy results, while bottom plots report the fairness gain results. Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different $\\beta$ values. For details of these values along with standard deviation numbers refer to Tables 7 and 8 in the Appendixes section.",
      "doc_b_visual_score": 3,
      "score": 9.5
    },
    {
      "doc_a": "1701.08230",
      "doc_b": "1907.06430",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1701.08230_1701.08230_fig_2_204",
      "doc_a_query": "Do the two distributions drawn from beta distributions with equal means in the right panel share the same peak location?",
      "doc_a_answer": "No, the blue curve peaks before 25% (near the dashed line) while the red curve peaks slightly after 25%, despite both distributions having equal means as stated.",
      "doc_a_visual_anchor": "Blue and red curves with vertical dashed line at 25% in top-right simulated panel",
      "doc_a_text_evidence": "simulated data drawn from two beta distributions with equal means (right)",
      "doc_a_figure_id": "1701.08230_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg",
      "doc_a_caption": "Figure 1: Top: distribution of risk scores for Broward County data (le), and simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains $3 0 \\%$ of defendants in Broward County violates statistical parity (as measured by detention rate), predictive equality (false positive rate), and conditional statistical parity (detention rate conditional on number of prior arrests). We omit the last measure for the simulated data since that would require making additional assumptions about the relationship of priors and risk in the hypothetical populations.",
      "doc_a_visual_score": 5,
      "doc_b_query_id": "l1_1907.06430_1907.06430_fig_11_860",
      "doc_b_query": "Does the red solid arrow from A to Y represent the direct path whose unfairness is quantified by path-specific effect?",
      "doc_b_answer": "Yes, the red solid arrow from A to Y represents the direct path A → Y, whose unfairness is quantified by the path-specific effect PSE^aa when the path A → D → Y is considered fair.",
      "doc_b_visual_anchor": "red solid arrow from node A to node Y",
      "doc_b_text_evidence": "in which the path $A $ $D  Y$ is considered fair, unfairness can instead be quantified with the path-specific effect along the direct path $A  Y$ , PSE $^ { a a }$",
      "doc_b_figure_id": "1907.06430_fig_11",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1907.06430/1907.06430/hybrid_auto/images/1907.06430_page0_fig10.jpg",
      "doc_b_caption": "Fig. 7. CBN underlying a college admission scenario.",
      "doc_b_visual_score": 4,
      "score": 9.5
    },
    {
      "doc_a": "1701.08230",
      "doc_b": "1705.10378",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1701.08230_1701.08230_fig_2_204",
      "doc_a_query": "Do the two distributions drawn from beta distributions with equal means in the right panel share the same peak location?",
      "doc_a_answer": "No, the blue curve peaks before 25% (near the dashed line) while the red curve peaks slightly after 25%, despite both distributions having equal means as stated.",
      "doc_a_visual_anchor": "Blue and red curves with vertical dashed line at 25% in top-right simulated panel",
      "doc_a_text_evidence": "simulated data drawn from two beta distributions with equal means (right)",
      "doc_a_figure_id": "1701.08230_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg",
      "doc_a_caption": "Figure 1: Top: distribution of risk scores for Broward County data (le), and simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains $3 0 \\%$ of defendants in Broward County violates statistical parity (as measured by detention rate), predictive equality (false positive rate), and conditional statistical parity (detention rate conditional on number of prior arrests). We omit the last measure for the simulated data since that would require making additional assumptions about the relationship of priors and risk in the hypothetical populations.",
      "doc_a_visual_score": 5,
      "doc_b_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_b_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_b_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_b_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_b_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_b_figure_id": "1705.10378_fig_1",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_b_visual_score": 3,
      "score": 9.0
    },
    {
      "doc_a": "1706.02744",
      "doc_b": "1809.02244",
      "shared_entity_count": 1,
      "shared_entities": [
        "dag"
      ],
      "doc_a_query_id": "l1_1706.02744_1706.02744_fig_4_242",
      "doc_a_query": "Why does the intervened graph remove the edge from green A to red P when proxy discrimination is being avoided?",
      "doc_a_answer": "The benevolent viewpoint aims to guarantee that proxy P has no overall influence on prediction by adjusting P→R to cancel influence along P→X→R, requiring intervention on the A→P edge.",
      "doc_a_visual_anchor": "removed edge from green node A to red node P in the right graph",
      "doc_a_text_evidence": "we want to guarantee that the proxy $P$ has no overall influence on the prediction, by adjusting $P  R$ to cancel the influence along $P $ $X  R$ in the intervened graph",
      "doc_a_figure_id": "1706.02744_fig_4",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1706.02744/1706.02744/hybrid_auto/images/1706.02744_page0_fig3.jpg",
      "doc_a_caption": "Figure 3: A template graph $\\tilde { \\mathcal { G } }$ for proxy discrimination (left) with its intervened version $\\mathcal { G }$ (right). While from the benevolent viewpoint we do not generically prohibit any influence from $A$ on $R$ , we want to guarantee that the proxy $P$ has no overall influence on the prediction, by adjusting $P  R$ to cancel the influence along $P $ $X  R$ in the intervened graph.",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_b_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_b_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_b_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_b_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_b_figure_id": "1809.02244_fig_4",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_b_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_b_visual_score": 4,
      "score": 9.0
    },
    {
      "doc_a": "1810.01943",
      "doc_b": "2109.03952",
      "shared_entity_count": 2,
      "shared_entities": [
        "accuracy",
        "spd"
      ],
      "doc_a_query_id": "l1_1810.01943_1810.01943_fig_2_569",
      "doc_a_query": "Why does the bar at 32-37 exceed 0.20 when the localization approach targets the 43-58 range in older groups?",
      "doc_a_answer": "The figure shows the younger (unprivileged) group where the 17-27 range is localized. The 43-58 range applies to the separate older (privileged) group analysis, not shown in this panel.",
      "doc_a_visual_anchor": "tallest blue bar at age 32-37 reaching approximately 0.25",
      "doc_a_text_evidence": "The 17–27 range in the younger group and the 43–58 range in the older group would be localized by the approach.",
      "doc_a_figure_id": "1810.01943_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig1.jpg",
      "doc_a_caption": "Figure 2. Protected attribute bias localization in (a) younger (unprivileged), and (b) older (privileged) groups in the German Credit dataset. The 17–27 range in the younger group and the 43– 58 range in the older group would be localized by the approach.",
      "doc_a_visual_score": 2,
      "doc_b_query_id": "l1_2109.03952_2109.03952_fig_1_947",
      "doc_b_query": "Why do the red boxes e1 through em have dimension d^e before entering the orange Attention layer?",
      "doc_b_answer": "Each feature value is treated as an individual entity and learns a fixed-size embedding vector in R^(d^e), similar to how words are embedded in text classification tasks.",
      "doc_b_visual_anchor": "red boxes labeled e1, e2, ..., em positioned between blue circles and orange Attention layer",
      "doc_b_text_evidence": "We consider each feature value as an individual entity (like the words are considered in text-classification) and learn a fixed-size embedding {e_k}_{k=1}^m, e_k ∈ R^{d^e} for each feature, {f_k}_{k=1}^m",
      "doc_b_figure_id": "2109.03952_fig_1",
      "doc_b_figure_type": "architecture",
      "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: (a) In general classification model, for each feature $f _ { k }$ a vector representation $e _ { k }$ of length $d ^ { e }$ is learned. This is passed to the attention layer which produces a $d ^ { e }$ - dimensional vector representation for the sample instance $i$ which is passed to two dense layers to get the final classification output. (b) The Attribution framework has the same architecture as the general model. One outcome is obtained through the original model and another through the model that has some attention weights zeroed. The observed difference in accuracy and fairness measures will indicate the effect of the zeroed out features on accuracy and fairness.",
      "doc_b_visual_score": 3,
      "score": 8.5
    },
    {
      "doc_a": "1905.10674",
      "doc_b": "1906.02589",
      "shared_entity_count": 2,
      "shared_entities": [
        "accuracy",
        "mlp"
      ],
      "doc_a_query_id": "l1_1905.10674_1905.10674_fig_5_810",
      "doc_a_query": "At which λ value does the compositional adversary's gender prediction performance reach its minimum on MovieLens1M?",
      "doc_a_answer": "The compositional adversary achieves its minimum Gender AUC of approximately 0.51 at λ=1000, representing the strongest tradeoff point before slight recovery at higher λ values.",
      "doc_a_visual_anchor": "lowest point of solid blue curve at λ=1000 with AUC ≈ 0.51",
      "doc_a_text_evidence": "Tradeoff of Gender AUC score on MovieLens1M for a compositional adversary versus different λ",
      "doc_a_figure_id": "1905.10674_fig_5",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1905.10674/1905.10674/hybrid_auto/images/1905.10674_page0_fig4.jpg",
      "doc_a_caption": "Figure 5. Tradeoff of Gender AUC score on MovieLens1M for a compositional adversary versus different $\\lambda$",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_1906.02589_1906.02589_fig_29_835",
      "doc_b_query": "Why does the solid blue TEXAS line maintain higher accuracy than dashed orange X-VAE across all Δ_CP values when predicting Heavy-Makeup?",
      "doc_b_answer": "FFVAE's structured latent code using multiple sensitive attributes (Chubby, Eyeglasses, Male) enables better disentanglement, aligning with subgroup fair machine learning goals more effectively than X-VAE's approach.",
      "doc_b_visual_anchor": "solid blue TEXAS line consistently above dashed orange X-VAE line from Δ_CP 0.00 to 0.40",
      "doc_b_text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes",
      "doc_b_figure_id": "1906.02589_fig_29",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg",
      "doc_b_caption": "Figure 5. Celeb-A subgroup fair classification results. Sensitive attributes: Chubby (C), Eyeglasses (E), and Male (M). $y =$ Heavy-Makeup.",
      "doc_b_visual_score": 5,
      "score": 8.5
    },
    {
      "doc_a": "1805.09458",
      "doc_b": "1809.10083",
      "shared_entity_count": 2,
      "shared_entities": [
        "mnist",
        "sne"
      ],
      "doc_a_query_id": "l1_1805.09458_1805.09458_fig_1_439",
      "doc_a_query": "Does the VFAE salmon bar at 0.75 adversarial loss indicate the encoder-decoder pair uses Gaussian reparameterization?",
      "doc_a_answer": "Yes, VFAE's modified loss (Eq. 18) requires learning an encoder-decoder pair q(z|x) and p(x|z,c) where the encoder q(z|x) uses the Gaussian reparameterization trick, as shown by the 0-layer result.",
      "doc_a_visual_anchor": "VFAE group salmon/red bar at approximately 0.75 adversarial loss",
      "doc_a_text_evidence": "We have two modified VAE loss (Eq. 18) and modified VIB loss (Eq. 31). In both we have to learn an encoder and decoder pair $q ( z | x )$ and $p ( x | z , c )$ . We use feed forward networks to approximate these functions. For $q ( z | x )$ we use the Gaussian reparameterization trick",
      "doc_a_figure_id": "1805.09458_fig_1",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: On the left we display the adversarial loss (the accuracy of the adversary on $c$ ) and predictive accurracy on $y$ for three methods, plus the majority-class baseline, on both Adult and German datasets. For adv. loss lower is better, while for pred. acc. higher is better. On the right we plot adversarial loss by varying adversarial strength (indicated by color), parameterized by the number of layers from zero (logistic regression) to three. All evaluations are performed on the hold-out test sets.",
      "doc_a_visual_score": 2,
      "doc_b_query_id": "l1_1809.10083_1809.10083_fig_16_555",
      "doc_b_query": "Why does the blue cluster at x=-45.0 show tighter grouping than the red cluster at x=45.0 in this embedding?",
      "doc_b_answer": "The visualization shows e₁ labeled by subject-ID with numerical markers. The tighter blue clustering likely reflects better subject-ID separation in this region of the embedding space compared to the more dispersed red region.",
      "doc_b_visual_anchor": "Blue cluster at x=-45.0 versus red cluster at x=45.0",
      "doc_b_text_evidence": "Figure 2 shows t-SNE [15] visualization of raw data and embeddings e₁ and e₂ for our model.",
      "doc_b_figure_id": "1809.10083_fig_16",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.10083/1809.10083/hybrid_auto/images/1809.10083_page0_fig15.jpg",
      "doc_b_caption": "Table 2: Results on Chairs. High $A _ { y }$ and low $A _ { z }$ are desired.   ",
      "doc_b_visual_score": 3,
      "score": 8.5
    },
    {
      "doc_a": "1511.00830",
      "doc_b": "1802.08139",
      "shared_entity_count": 1,
      "shared_entities": [
        "mmd"
      ],
      "doc_a_query_id": "l1_1511.00830_1511.00830_fig_13_73",
      "doc_a_query": "Why do the blue and red points heavily overlap in this visualization, given the model uses both s and MMD?",
      "doc_a_answer": "The model successfully factors out domain (gender) information by incorporating both the sensitive attribute s and MMD regularization, resulting in representations where male and female samples are not separable and cluster together, demonstrating fairness through indistinguishability.",
      "doc_a_visual_anchor": "overlapping blue (male) and red (female) scattered point clusters",
      "doc_a_text_evidence": "Our model was successful in factoring out the domain information, since the accuracy, measured both linearly (LR) and non-linearly (RF), was towards random chance",
      "doc_a_figure_id": "1511.00830_fig_13",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig12.jpg",
      "doc_a_caption": "Figure 4: t-SNE (van der Maaten, 2013) visualizations from the Adult dataset on: (a): original x , (b): latent $\\mathbf { z } _ { 1 }$ without s and MMD, (c): latent $\\mathbf { z } _ { 1 }$ with s and without MMD, (d): latent $\\mathbf { z } _ { 1 }$ with s and MMD. Blue colour corresponds to males whereas red colour corresponds to females.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1802.08139_1802.08139_fig_17_356",
      "doc_b_query": "Why does the gray node C in subfigure (a) become a red bidirected link in the ADMG representation?",
      "doc_b_answer": "The gray node C represents an unobserved confounder. In ADMG notation, unobserved common causes are indicated by red bidirected links between the affected variables, which is why C's influence is shown as a red bidirected edge in subfigure (b).",
      "doc_b_visual_anchor": "Gray node C in subfigure (a) and red bidirected edge in subfigure (b)",
      "doc_b_text_evidence": "An ADMG is a causal graph containing two kinds of links, directed links (either green or black depending on whether we are interested in the corresponding causal path), and red bidirected links, indicating the presence of an unobserved common cause.",
      "doc_b_figure_id": "1802.08139_fig_17",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1802.08139/1802.08139/hybrid_auto/images/1802.08139_page0_fig16.jpg",
      "doc_b_caption": "Figure 7. (a): GCM with an unobserved confounder $C$ indicated with a gray node. (b): ADMG corresponding to (a). The causal effect along the green path $A  Y$ cannot be identified by only using observed variables.",
      "doc_b_visual_score": 4,
      "score": 8.5
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "1907.06430",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1907.06430_1907.06430_fig_11_860",
      "doc_b_query": "Does the red solid arrow from A to Y represent the direct path whose unfairness is quantified by path-specific effect?",
      "doc_b_answer": "Yes, the red solid arrow from A to Y represents the direct path A → Y, whose unfairness is quantified by the path-specific effect PSE^aa when the path A → D → Y is considered fair.",
      "doc_b_visual_anchor": "red solid arrow from node A to node Y",
      "doc_b_text_evidence": "in which the path $A $ $D  Y$ is considered fair, unfairness can instead be quantified with the path-specific effect along the direct path $A  Y$ , PSE $^ { a a }$",
      "doc_b_figure_id": "1907.06430_fig_11",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1907.06430/1907.06430/hybrid_auto/images/1907.06430_page0_fig10.jpg",
      "doc_b_caption": "Fig. 7. CBN underlying a college admission scenario.",
      "doc_b_visual_score": 4,
      "score": 8.5
    },
    {
      "doc_a": "1705.10378",
      "doc_b": "1809.02244",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_a_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_a_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_a_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_a_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_a_figure_id": "1705.10378_fig_1",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_b_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_b_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_b_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_b_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_b_figure_id": "1809.02244_fig_4",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_b_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_b_visual_score": 4,
      "score": 8.5
    },
    {
      "doc_a": "1907.06430",
      "doc_b": "2005.07293",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1907.06430_1907.06430_fig_11_860",
      "doc_a_query": "Does the red solid arrow from A to Y represent the direct path whose unfairness is quantified by path-specific effect?",
      "doc_a_answer": "Yes, the red solid arrow from A to Y represents the direct path A → Y, whose unfairness is quantified by the path-specific effect PSE^aa when the path A → D → Y is considered fair.",
      "doc_a_visual_anchor": "red solid arrow from node A to node Y",
      "doc_a_text_evidence": "in which the path $A $ $D  Y$ is considered fair, unfairness can instead be quantified with the path-specific effect along the direct path $A  Y$ , PSE $^ { a a }$",
      "doc_a_figure_id": "1907.06430_fig_11",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1907.06430/1907.06430/hybrid_auto/images/1907.06430_page0_fig10.jpg",
      "doc_a_caption": "Fig. 7. CBN underlying a college admission scenario.",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_2005.07293_2005.07293_fig_3_909",
      "doc_b_query": "Do the near-flat red and green lines at 84% across all beta values support consistent performance across random splits?",
      "doc_b_answer": "Yes, the flat Parity and Classifier lines demonstrate consistent performance. Each point represents the average value of 10 experiments performed on the same 10 random splits across different beta values, ensuring robustness.",
      "doc_b_visual_anchor": "Red line with X markers and green line with triangle markers both maintaining approximately 84-85% accuracy from beta=0 to beta=0.9",
      "doc_b_text_evidence": "Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different beta values.",
      "doc_b_figure_id": "2005.07293_fig_3",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig2.jpg",
      "doc_b_caption": "Figure 2: Accuracy and fairness gain results for the COMPAS and Adult datasets over different $\\beta$ values. Top plots report the accuracy results, while bottom plots report the fairness gain results. Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different $\\beta$ values. For details of these values along with standard deviation numbers refer to Tables 7 and 8 in the Appendixes section.",
      "doc_b_visual_score": 3,
      "score": 8.5
    },
    {
      "doc_a": "1703.06856",
      "doc_b": "1706.02744",
      "shared_entity_count": 1,
      "shared_entities": [
        "dag"
      ],
      "doc_a_query_id": "l1_1703.06856_1703.06856_fig_9_223",
      "doc_a_query": "How does the fourth plot's increased red dot density in the yellow-circled region demonstrate racial effects on arrest outcomes?",
      "doc_a_answer": "The fourth plot shows the counterfactual where everyone is treated as Black Hispanic, resulting in more arrests (red dots) compared to other scenarios, demonstrating that race significantly affects arrest likelihood in the model.",
      "doc_a_visual_anchor": "Fourth plot 'Arrest if Black Hispanic (counterfactual)' showing higher concentration of red dots in yellow-circled northern region",
      "doc_a_text_evidence": "Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_figure_id": "1703.06856_fig_9",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1703.06856/1703.06856/hybrid_auto/images/1703.06856_page0_fig8.jpg",
      "doc_a_caption": "Figure 4: How race affects arrest. The above maps show how altering one’s race affects whether or not they will be arrested, according to the model. The left-most plot shows the distribution of White and Black Hispanic populations in the stop-and-frisk dataset. The second plot shows the true arrests for all of the stops. Given our model we can compute whether or not every individual in the dataset would be arrest had they been white. We show this counterfactual in the third plot. Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1706.02744_1706.02744_fig_4_242",
      "doc_b_query": "Why does the intervened graph remove the edge from green A to red P when proxy discrimination is being avoided?",
      "doc_b_answer": "The benevolent viewpoint aims to guarantee that proxy P has no overall influence on prediction by adjusting P→R to cancel influence along P→X→R, requiring intervention on the A→P edge.",
      "doc_b_visual_anchor": "removed edge from green node A to red node P in the right graph",
      "doc_b_text_evidence": "we want to guarantee that the proxy $P$ has no overall influence on the prediction, by adjusting $P  R$ to cancel the influence along $P $ $X  R$ in the intervened graph",
      "doc_b_figure_id": "1706.02744_fig_4",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1706.02744/1706.02744/hybrid_auto/images/1706.02744_page0_fig3.jpg",
      "doc_b_caption": "Figure 3: A template graph $\\tilde { \\mathcal { G } }$ for proxy discrimination (left) with its intervened version $\\mathcal { G }$ (right). While from the benevolent viewpoint we do not generically prohibit any influence from $A$ on $R$ , we want to guarantee that the proxy $P$ has no overall influence on the prediction, by adjusting $P  R$ to cancel the influence along $P $ $X  R$ in the intervened graph.",
      "doc_b_visual_score": 4,
      "score": 8.5
    },
    {
      "doc_a": "1802.08139",
      "doc_b": "2109.03952",
      "shared_entity_count": 1,
      "shared_entities": [
        "uci"
      ],
      "doc_a_query_id": "l1_1802.08139_1802.08139_fig_17_356",
      "doc_a_query": "Why does the gray node C in subfigure (a) become a red bidirected link in the ADMG representation?",
      "doc_a_answer": "The gray node C represents an unobserved confounder. In ADMG notation, unobserved common causes are indicated by red bidirected links between the affected variables, which is why C's influence is shown as a red bidirected edge in subfigure (b).",
      "doc_a_visual_anchor": "Gray node C in subfigure (a) and red bidirected edge in subfigure (b)",
      "doc_a_text_evidence": "An ADMG is a causal graph containing two kinds of links, directed links (either green or black depending on whether we are interested in the corresponding causal path), and red bidirected links, indicating the presence of an unobserved common cause.",
      "doc_a_figure_id": "1802.08139_fig_17",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1802.08139/1802.08139/hybrid_auto/images/1802.08139_page0_fig16.jpg",
      "doc_a_caption": "Figure 7. (a): GCM with an unobserved confounder $C$ indicated with a gray node. (b): ADMG corresponding to (a). The causal effect along the green path $A  Y$ cannot be identified by only using observed variables.",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_2109.03952_2109.03952_fig_1_947",
      "doc_b_query": "Why do the red boxes e1 through em have dimension d^e before entering the orange Attention layer?",
      "doc_b_answer": "Each feature value is treated as an individual entity and learns a fixed-size embedding vector in R^(d^e), similar to how words are embedded in text classification tasks.",
      "doc_b_visual_anchor": "red boxes labeled e1, e2, ..., em positioned between blue circles and orange Attention layer",
      "doc_b_text_evidence": "We consider each feature value as an individual entity (like the words are considered in text-classification) and learn a fixed-size embedding {e_k}_{k=1}^m, e_k ∈ R^{d^e} for each feature, {f_k}_{k=1}^m",
      "doc_b_figure_id": "2109.03952_fig_1",
      "doc_b_figure_type": "architecture",
      "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: (a) In general classification model, for each feature $f _ { k }$ a vector representation $e _ { k }$ of length $d ^ { e }$ is learned. This is passed to the attention layer which produces a $d ^ { e }$ - dimensional vector representation for the sample instance $i$ which is passed to two dense layers to get the final classification output. (b) The Attribution framework has the same architecture as the general model. One outcome is obtained through the original model and another through the model that has some attention weights zeroed. The observed difference in accuracy and fairness measures will indicate the effect of the zeroed out features on accuracy and fairness.",
      "doc_b_visual_score": 3,
      "score": 8.5
    },
    {
      "doc_a": "1703.06856",
      "doc_b": "1901.10436",
      "shared_entity_count": 1,
      "shared_entities": [
        "map"
      ],
      "doc_a_query_id": "l1_1703.06856_1703.06856_fig_9_223",
      "doc_a_query": "How does the fourth plot's increased red dot density in the yellow-circled region demonstrate racial effects on arrest outcomes?",
      "doc_a_answer": "The fourth plot shows the counterfactual where everyone is treated as Black Hispanic, resulting in more arrests (red dots) compared to other scenarios, demonstrating that race significantly affects arrest likelihood in the model.",
      "doc_a_visual_anchor": "Fourth plot 'Arrest if Black Hispanic (counterfactual)' showing higher concentration of red dots in yellow-circled northern region",
      "doc_a_text_evidence": "Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_figure_id": "1703.06856_fig_9",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1703.06856/1703.06856/hybrid_auto/images/1703.06856_page0_fig8.jpg",
      "doc_a_caption": "Figure 4: How race affects arrest. The above maps show how altering one’s race affects whether or not they will be arrested, according to the model. The left-most plot shows the distribution of White and Black Hispanic populations in the stop-and-frisk dataset. The second plot shows the true arrests for all of the stops. Given our model we can compute whether or not every individual in the dataset would be arrest had they been white. We show this counterfactual in the third plot. Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1901.10436_1901.10436_fig_5_700",
      "doc_b_query": "How does the blue segment 'a' connecting yellow points C1 and C2 relate to craniofacial ratio features?",
      "doc_b_answer": "The craniofacial ratio features used mapped DLIB key-points as facial landmarks, with eight dimensions summarized in Table 8, similar to the inner canthus points shown.",
      "doc_b_visual_anchor": "Blue line segment 'a' connecting yellow points C1 and C2",
      "doc_b_text_evidence": "Similar to the above features, the craniofacial ratios used the mapped DLIB key-points as facial landmarks. Table 8 summarizes the eight dimensions of the craniofacial ratio features.",
      "doc_b_figure_id": "1901.10436_fig_5",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1901.10436/1901.10436/hybrid_auto/images/1901.10436_page0_fig4.jpg",
      "doc_b_caption": "Figure 3: Process for extracting facial symmetry measures for coding scheme 4, starting with (a) rectified face showing face mid-line and reference points for inner canthus (C1 and C2) and philtrum (C3) and line segmented connecting them (point $a$ for C1-C2 and point $b$ connecting C3 to the midpoint of point $a$ ). Additionally, a Sobel filter is used to extract (b) edge magnitude and (c) orientation to derive the measure for edge orientation similarity.",
      "doc_b_visual_score": 3,
      "score": 8.0
    },
    {
      "doc_a": "1805.03094",
      "doc_b": "1901.10436",
      "shared_entity_count": 1,
      "shared_entities": [
        "map"
      ],
      "doc_a_query_id": "l1_1805.03094_1805.03094_fig_2_397",
      "doc_a_query": "Why does the red topmost curve maintain acceptance probability near 0.45 while blue drops below 0.25 across answer positions?",
      "doc_a_answer": "The horizontal bands correspond to different subgroups conditioned on total number of answers the user has written, showing performance variation across experience levels as answer position increases.",
      "doc_a_visual_anchor": "red topmost curve at ~0.45 probability versus blue bottom curve at ~0.25 probability",
      "doc_a_text_evidence": "the horizontal bands corresponding to the different subgroups, conditioned on total number of answers the user has written",
      "doc_a_figure_id": "1805.03094_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1805.03094/1805.03094/hybrid_auto/images/1805.03094_page0_fig1.jpg",
      "doc_a_caption": "Figure 1: Disaggregation of Stack Exchange data. (a) The heat map shows the probability the answer is accepted as a function of its answer position within a session, with the horizontal bands corresponding to the different subgroups, conditioned on total number of answers the user has written. (b) Number of data samples within each bin of the heat map. Note that the outcome becomes noisy when there are few samples. The trends in performance as a function of answer position in (c) disaggregated data and (d) aggregate data. Error bars in (c) and (d) show $9 5 \\%$ confidence interval.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1901.10436_1901.10436_fig_5_700",
      "doc_b_query": "How does the blue segment 'a' connecting yellow points C1 and C2 relate to craniofacial ratio features?",
      "doc_b_answer": "The craniofacial ratio features used mapped DLIB key-points as facial landmarks, with eight dimensions summarized in Table 8, similar to the inner canthus points shown.",
      "doc_b_visual_anchor": "Blue line segment 'a' connecting yellow points C1 and C2",
      "doc_b_text_evidence": "Similar to the above features, the craniofacial ratios used the mapped DLIB key-points as facial landmarks. Table 8 summarizes the eight dimensions of the craniofacial ratio features.",
      "doc_b_figure_id": "1901.10436_fig_5",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1901.10436/1901.10436/hybrid_auto/images/1901.10436_page0_fig4.jpg",
      "doc_b_caption": "Figure 3: Process for extracting facial symmetry measures for coding scheme 4, starting with (a) rectified face showing face mid-line and reference points for inner canthus (C1 and C2) and philtrum (C3) and line segmented connecting them (point $a$ for C1-C2 and point $b$ connecting C3 to the midpoint of point $a$ ). Additionally, a Sobel filter is used to extract (b) edge magnitude and (c) orientation to derive the measure for edge orientation similarity.",
      "doc_b_visual_score": 3,
      "score": 8.0
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "1705.10378",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_b_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_b_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_b_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_b_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_b_figure_id": "1705.10378_fig_1",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_b_visual_score": 3,
      "score": 8.0
    },
    {
      "doc_a": "1705.10378",
      "doc_b": "2005.07293",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_a_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_a_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_a_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_a_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_a_figure_id": "1705.10378_fig_1",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_2005.07293_2005.07293_fig_3_909",
      "doc_b_query": "Do the near-flat red and green lines at 84% across all beta values support consistent performance across random splits?",
      "doc_b_answer": "Yes, the flat Parity and Classifier lines demonstrate consistent performance. Each point represents the average value of 10 experiments performed on the same 10 random splits across different beta values, ensuring robustness.",
      "doc_b_visual_anchor": "Red line with X markers and green line with triangle markers both maintaining approximately 84-85% accuracy from beta=0 to beta=0.9",
      "doc_b_text_evidence": "Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different beta values.",
      "doc_b_figure_id": "2005.07293_fig_3",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig2.jpg",
      "doc_b_caption": "Figure 2: Accuracy and fairness gain results for the COMPAS and Adult datasets over different $\\beta$ values. Top plots report the accuracy results, while bottom plots report the fairness gain results. Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different $\\beta$ values. For details of these values along with standard deviation numbers refer to Tables 7 and 8 in the Appendixes section.",
      "doc_b_visual_score": 3,
      "score": 8.0
    },
    {
      "doc_a": "1705.10378",
      "doc_b": "2109.03952",
      "shared_entity_count": 1,
      "shared_entities": [
        "uci"
      ],
      "doc_a_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_a_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_a_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_a_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_a_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_a_figure_id": "1705.10378_fig_1",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_2109.03952_2109.03952_fig_1_947",
      "doc_b_query": "Why do the red boxes e1 through em have dimension d^e before entering the orange Attention layer?",
      "doc_b_answer": "Each feature value is treated as an individual entity and learns a fixed-size embedding vector in R^(d^e), similar to how words are embedded in text classification tasks.",
      "doc_b_visual_anchor": "red boxes labeled e1, e2, ..., em positioned between blue circles and orange Attention layer",
      "doc_b_text_evidence": "We consider each feature value as an individual entity (like the words are considered in text-classification) and learn a fixed-size embedding {e_k}_{k=1}^m, e_k ∈ R^{d^e} for each feature, {f_k}_{k=1}^m",
      "doc_b_figure_id": "2109.03952_fig_1",
      "doc_b_figure_type": "architecture",
      "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: (a) In general classification model, for each feature $f _ { k }$ a vector representation $e _ { k }$ of length $d ^ { e }$ is learned. This is passed to the attention layer which produces a $d ^ { e }$ - dimensional vector representation for the sample instance $i$ which is passed to two dense layers to get the final classification output. (b) The Attribution framework has the same architecture as the general model. One outcome is obtained through the original model and another through the model that has some attention weights zeroed. The observed difference in accuracy and fairness measures will indicate the effect of the zeroed out features on accuracy and fairness.",
      "doc_b_visual_score": 3,
      "score": 8.0
    },
    {
      "doc_a": "1602.05352",
      "doc_b": "1905.10674",
      "shared_entity_count": 2,
      "shared_entities": [
        "accuracy",
        "rmse"
      ],
      "doc_a_query_id": "l1_1602.05352_1602.05352_fig_5_88",
      "doc_a_query": "Why does the blue MF-IPS curve achieve lower MSE than red MF-Naive across all alpha values?",
      "doc_a_answer": "MF-IPS uses propensity weighting to correct for selection bias, while MF-Naive does not account for biased observations. This allows MF-IPS to achieve better prediction accuracy through improved risk estimation.",
      "doc_a_visual_anchor": "blue MF-IPS curve consistently below red MF-Naive curve across alpha from 0 to 1",
      "doc_a_text_evidence": "Using the same semi-synthetic ML100K dataset and observation model as above, we compare our matrix factorization MF-IPS with the traditional unweighted matrix factorization MF-Naive.",
      "doc_a_figure_id": "1602.05352_fig_5",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1602.05352/1602.05352/hybrid_auto/images/1602.05352_page0_fig4.jpg",
      "doc_a_caption": "Figure 3. Prediction error (MSE) of matrix factorization methods as the observed ratings exhibit varying degrees of selection bias (left) and as propensity estimation quality degrades (right).",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1905.10674_1905.10674_fig_5_810",
      "doc_b_query": "At which λ value does the compositional adversary's gender prediction performance reach its minimum on MovieLens1M?",
      "doc_b_answer": "The compositional adversary achieves its minimum Gender AUC of approximately 0.51 at λ=1000, representing the strongest tradeoff point before slight recovery at higher λ values.",
      "doc_b_visual_anchor": "lowest point of solid blue curve at λ=1000 with AUC ≈ 0.51",
      "doc_b_text_evidence": "Tradeoff of Gender AUC score on MovieLens1M for a compositional adversary versus different λ",
      "doc_b_figure_id": "1905.10674_fig_5",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1905.10674/1905.10674/hybrid_auto/images/1905.10674_page0_fig4.jpg",
      "doc_b_caption": "Figure 5. Tradeoff of Gender AUC score on MovieLens1M for a compositional adversary versus different $\\lambda$",
      "doc_b_visual_score": 4,
      "score": 7.5
    },
    {
      "doc_a": "1805.09458",
      "doc_b": "1906.02589",
      "shared_entity_count": 2,
      "shared_entities": [
        "accuracy",
        "vae"
      ],
      "doc_a_query_id": "l1_1805.09458_1805.09458_fig_1_439",
      "doc_a_query": "Does the VFAE salmon bar at 0.75 adversarial loss indicate the encoder-decoder pair uses Gaussian reparameterization?",
      "doc_a_answer": "Yes, VFAE's modified loss (Eq. 18) requires learning an encoder-decoder pair q(z|x) and p(x|z,c) where the encoder q(z|x) uses the Gaussian reparameterization trick, as shown by the 0-layer result.",
      "doc_a_visual_anchor": "VFAE group salmon/red bar at approximately 0.75 adversarial loss",
      "doc_a_text_evidence": "We have two modified VAE loss (Eq. 18) and modified VIB loss (Eq. 31). In both we have to learn an encoder and decoder pair $q ( z | x )$ and $p ( x | z , c )$ . We use feed forward networks to approximate these functions. For $q ( z | x )$ we use the Gaussian reparameterization trick",
      "doc_a_figure_id": "1805.09458_fig_1",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: On the left we display the adversarial loss (the accuracy of the adversary on $c$ ) and predictive accurracy on $y$ for three methods, plus the majority-class baseline, on both Adult and German datasets. For adv. loss lower is better, while for pred. acc. higher is better. On the right we plot adversarial loss by varying adversarial strength (indicated by color), parameterized by the number of layers from zero (logistic regression) to three. All evaluations are performed on the hold-out test sets.",
      "doc_a_visual_score": 2,
      "doc_b_query_id": "l1_1906.02589_1906.02589_fig_29_835",
      "doc_b_query": "Why does the solid blue TEXAS line maintain higher accuracy than dashed orange X-VAE across all Δ_CP values when predicting Heavy-Makeup?",
      "doc_b_answer": "FFVAE's structured latent code using multiple sensitive attributes (Chubby, Eyeglasses, Male) enables better disentanglement, aligning with subgroup fair machine learning goals more effectively than X-VAE's approach.",
      "doc_b_visual_anchor": "solid blue TEXAS line consistently above dashed orange X-VAE line from Δ_CP 0.00 to 0.40",
      "doc_b_text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes",
      "doc_b_figure_id": "1906.02589_fig_29",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg",
      "doc_b_caption": "Figure 5. Celeb-A subgroup fair classification results. Sensitive attributes: Chubby (C), Eyeglasses (E), and Male (M). $y =$ Heavy-Makeup.",
      "doc_b_visual_score": 5,
      "score": 7.5
    },
    {
      "doc_a": "1608.07187",
      "doc_b": "1901.10436",
      "shared_entity_count": 1,
      "shared_entities": [
        "map"
      ],
      "doc_a_query_id": "l1_1608.07187_1608.07187_fig_3_131",
      "doc_a_query": "Does the heir-heiress vector relationship at horizontal position 0.1 exemplify the semantic relationships captured alongside countries-capitals and companies-CEOs?",
      "doc_a_answer": "Yes, the heir-heiress pair demonstrates the same type of algebraic vector relationship shown for gender pairs, which is analogous to other semantic relationships like countries and capitals or companies and CEOs mentioned in the methodology.",
      "doc_a_visual_anchor": "Dashed line connecting heir (y≈0.03) to heiress (y≈0.5) at horizontal position around 0.1",
      "doc_a_text_evidence": "Similar algebraic relationships have been shown for other semantic relationships, such as countries and their capital cities, companies and their CEOs, or simply different forms of the same word.",
      "doc_a_figure_id": "1608.07187_fig_3",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1608.07187/1608.07187/hybrid_auto/images/1608.07187_page0_fig2.jpg",
      "doc_a_caption": "Figure 3. A 2D projection (first two principal components) of the 300-dimensional vector space of the GloVe word embedding (Pennington et al., 2014). The lines illustrate algebraic relationships between related words: pairs of words that differ only by gender map to pairs of vectors whose vector difference is roughly constant. Similar algebraic relationships have been shown for other semantic relationships, such as countries and their capital cities, companies and their CEOs, or simply different forms of the same word.",
      "doc_a_visual_score": 2,
      "doc_b_query_id": "l1_1901.10436_1901.10436_fig_5_700",
      "doc_b_query": "How does the blue segment 'a' connecting yellow points C1 and C2 relate to craniofacial ratio features?",
      "doc_b_answer": "The craniofacial ratio features used mapped DLIB key-points as facial landmarks, with eight dimensions summarized in Table 8, similar to the inner canthus points shown.",
      "doc_b_visual_anchor": "Blue line segment 'a' connecting yellow points C1 and C2",
      "doc_b_text_evidence": "Similar to the above features, the craniofacial ratios used the mapped DLIB key-points as facial landmarks. Table 8 summarizes the eight dimensions of the craniofacial ratio features.",
      "doc_b_figure_id": "1901.10436_fig_5",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1901.10436/1901.10436/hybrid_auto/images/1901.10436_page0_fig4.jpg",
      "doc_b_caption": "Figure 3: Process for extracting facial symmetry measures for coding scheme 4, starting with (a) rectified face showing face mid-line and reference points for inner canthus (C1 and C2) and philtrum (C3) and line segmented connecting them (point $a$ for C1-C2 and point $b$ connecting C3 to the midpoint of point $a$ ). Additionally, a Sobel filter is used to extract (b) edge magnitude and (c) orientation to derive the measure for edge orientation similarity.",
      "doc_b_visual_score": 3,
      "score": 7.5
    },
    {
      "doc_a": "1701.08230",
      "doc_b": "1809.02244",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1701.08230_1701.08230_fig_2_204",
      "doc_a_query": "Do the two distributions drawn from beta distributions with equal means in the right panel share the same peak location?",
      "doc_a_answer": "No, the blue curve peaks before 25% (near the dashed line) while the red curve peaks slightly after 25%, despite both distributions having equal means as stated.",
      "doc_a_visual_anchor": "Blue and red curves with vertical dashed line at 25% in top-right simulated panel",
      "doc_a_text_evidence": "simulated data drawn from two beta distributions with equal means (right)",
      "doc_a_figure_id": "1701.08230_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg",
      "doc_a_caption": "Figure 1: Top: distribution of risk scores for Broward County data (le), and simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains $3 0 \\%$ of defendants in Broward County violates statistical parity (as measured by detention rate), predictive equality (false positive rate), and conditional statistical parity (detention rate conditional on number of prior arrests). We omit the last measure for the simulated data since that would require making additional assumptions about the relationship of priors and risk in the hypothetical populations.",
      "doc_a_visual_score": 5,
      "doc_b_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_b_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_b_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_b_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_b_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_b_figure_id": "1809.02244_fig_4",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_b_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_b_visual_score": 4,
      "score": 7.5
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "1610.08452",
      "shared_entity_count": 1,
      "shared_entities": [
        "fpr"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1610.08452_1610.08452_fig_9_182",
      "doc_b_query": "What causes the dashed boundary to separate more red circles from green ones compared to the solid boundary?",
      "doc_b_answer": "The fair constrained classifier shifts the decision boundary to equalize false positive and negative rates across groups, which the research compares against unconstrained classifiers to demonstrate performance trade-offs when avoiding disparate mistreatment.",
      "doc_b_visual_anchor": "dashed blue line positioned differently from solid cyan line relative to red and green markers",
      "doc_b_text_evidence": "Figure 4 summarizes the results by showing the decision boundaries for both the unconstrained classifiers (solid) and the fair constrained classifier (dashed) when controlling for disparate mistreatment",
      "doc_b_figure_id": "1610.08452_fig_9",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1610.08452/1610.08452/hybrid_auto/images/1610.08452_page0_fig8.jpg",
      "doc_b_caption": "Figure 4: [Synthetic data] $D _ { F P R }$ and $D _ { F N R }$ have the same sign. Removing disparate mistreatment on FPR can potentially increase disparate mistreatment on FNR. Removing disparate mistreatment on both at the same time causes a larger drop in accuracy.",
      "doc_b_visual_score": 6,
      "score": 7.5
    },
    {
      "doc_a": "1804.09301",
      "doc_b": "1910.10872",
      "shared_entity_count": 1,
      "shared_entities": [
        "nlp"
      ],
      "doc_a_query_id": "l1_1804.09301_1804.09301_fig_3_391",
      "doc_a_query": "Why do most blue data points lie below the dotted diagonal when Pearson correlation equals 0.67?",
      "doc_a_answer": "The Bergsma and Lin (2006) gender statistics are systematically male-skewed compared to Bureau of Labor Statistics, causing most points to fall below the 45-degree line despite positive correlation.",
      "doc_a_visual_anchor": "blue data points positioned below the dotted red 45-degree diagonal line",
      "doc_a_text_evidence": "although the gender statistics from B&L correlate with BLS employment statistics, they are systematically male-skewed (Figure 3)",
      "doc_a_figure_id": "1804.09301_fig_3",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1804.09301/1804.09301/hybrid_auto/images/1804.09301_page0_fig2.jpg",
      "doc_a_caption": "Figure 3: Gender statistics from Bergsma and Lin (2006) correlate with Bureau of Labor Statistics 2015. However, the former has systematically lower female percentages; most points lie well below the 45-degree line (dotted). Regression line and $9 5 \\%$ confidence interval in blue. Pearson $\\Gamma = 0 . 6 7$ .",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_1910.10872_1910.10872_fig_44_897",
      "doc_b_query": "Why does the V2.1 orange line remain higher than V2.0 green across all years if newer versions aimed to tag more entities?",
      "doc_b_answer": "The version update tried to tag more entities, resulting in more PERSON entities being incorrectly tagged as non-PERSON entities. This degraded performance with regard to Error Type-2 in the newer version, explaining the consistently higher error rates shown by the orange line.",
      "doc_b_visual_anchor": "V2.1 orange solid line consistently above V2.0 green dashed line from 1875 to 2015",
      "doc_b_text_evidence": "Version update in the CoreNLP model tried to tag more entities and thus a subtle boost in performance with regard to Error Type-3. However, this resulted in more PERSON entities being tagged as non-PERSON entities. This then degraded performance with regard to Error Type-2 in the newer version",
      "doc_b_figure_id": "1910.10872_fig_44",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1910.10872/1910.10872/hybrid_auto/images/1910.10872_page0_fig43.jpg",
      "doc_b_caption": "Figure 6: Biased performance of version 2.1 over 2.0 in 0 1875 1895 1915 1935 1955 1975 1995 2015Spacy medium. The bias against female names was on average twice that of male names.",
      "doc_b_visual_score": 5,
      "score": 7.5
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "1701.08230",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1701.08230_1701.08230_fig_2_204",
      "doc_b_query": "Do the two distributions drawn from beta distributions with equal means in the right panel share the same peak location?",
      "doc_b_answer": "No, the blue curve peaks before 25% (near the dashed line) while the red curve peaks slightly after 25%, despite both distributions having equal means as stated.",
      "doc_b_visual_anchor": "Blue and red curves with vertical dashed line at 25% in top-right simulated panel",
      "doc_b_text_evidence": "simulated data drawn from two beta distributions with equal means (right)",
      "doc_b_figure_id": "1701.08230_fig_2",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg",
      "doc_b_caption": "Figure 1: Top: distribution of risk scores for Broward County data (le), and simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains $3 0 \\%$ of defendants in Broward County violates statistical parity (as measured by detention rate), predictive equality (false positive rate), and conditional statistical parity (detention rate conditional on number of prior arrests). We omit the last measure for the simulated data since that would require making additional assumptions about the relationship of priors and risk in the hypothetical populations.",
      "doc_b_visual_score": 5,
      "score": 7.0
    },
    {
      "doc_a": "1701.08230",
      "doc_b": "2005.07293",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1701.08230_1701.08230_fig_2_204",
      "doc_a_query": "Do the two distributions drawn from beta distributions with equal means in the right panel share the same peak location?",
      "doc_a_answer": "No, the blue curve peaks before 25% (near the dashed line) while the red curve peaks slightly after 25%, despite both distributions having equal means as stated.",
      "doc_a_visual_anchor": "Blue and red curves with vertical dashed line at 25% in top-right simulated panel",
      "doc_a_text_evidence": "simulated data drawn from two beta distributions with equal means (right)",
      "doc_a_figure_id": "1701.08230_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg",
      "doc_a_caption": "Figure 1: Top: distribution of risk scores for Broward County data (le), and simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains $3 0 \\%$ of defendants in Broward County violates statistical parity (as measured by detention rate), predictive equality (false positive rate), and conditional statistical parity (detention rate conditional on number of prior arrests). We omit the last measure for the simulated data since that would require making additional assumptions about the relationship of priors and risk in the hypothetical populations.",
      "doc_a_visual_score": 5,
      "doc_b_query_id": "l1_2005.07293_2005.07293_fig_3_909",
      "doc_b_query": "Do the near-flat red and green lines at 84% across all beta values support consistent performance across random splits?",
      "doc_b_answer": "Yes, the flat Parity and Classifier lines demonstrate consistent performance. Each point represents the average value of 10 experiments performed on the same 10 random splits across different beta values, ensuring robustness.",
      "doc_b_visual_anchor": "Red line with X markers and green line with triangle markers both maintaining approximately 84-85% accuracy from beta=0 to beta=0.9",
      "doc_b_text_evidence": "Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different beta values.",
      "doc_b_figure_id": "2005.07293_fig_3",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig2.jpg",
      "doc_b_caption": "Figure 2: Accuracy and fairness gain results for the COMPAS and Adult datasets over different $\\beta$ values. Top plots report the accuracy results, while bottom plots report the fairness gain results. Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different $\\beta$ values. For details of these values along with standard deviation numbers refer to Tables 7 and 8 in the Appendixes section.",
      "doc_b_visual_score": 3,
      "score": 7.0
    },
    {
      "doc_a": "1610.08452",
      "doc_b": "1810.03993",
      "shared_entity_count": 1,
      "shared_entities": [
        "fpr"
      ],
      "doc_a_query_id": "l1_1610.08452_1610.08452_fig_9_182",
      "doc_a_query": "What causes the dashed boundary to separate more red circles from green ones compared to the solid boundary?",
      "doc_a_answer": "The fair constrained classifier shifts the decision boundary to equalize false positive and negative rates across groups, which the research compares against unconstrained classifiers to demonstrate performance trade-offs when avoiding disparate mistreatment.",
      "doc_a_visual_anchor": "dashed blue line positioned differently from solid cyan line relative to red and green markers",
      "doc_a_text_evidence": "Figure 4 summarizes the results by showing the decision boundaries for both the unconstrained classifiers (solid) and the fair constrained classifier (dashed) when controlling for disparate mistreatment",
      "doc_a_figure_id": "1610.08452_fig_9",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.08452/1610.08452/hybrid_auto/images/1610.08452_page0_fig8.jpg",
      "doc_a_caption": "Figure 4: [Synthetic data] $D _ { F P R }$ and $D _ { F N R }$ have the same sign. Removing disparate mistreatment on FPR can potentially increase disparate mistreatment on FNR. Removing disparate mistreatment on both at the same time causes a larger drop in accuracy.",
      "doc_a_visual_score": 6,
      "doc_b_query_id": "l1_1810.03993_1810.03993_fig_1_622",
      "doc_b_query": "Why does old-male reach the highest false positive rate near 0.08 when analyzing public figures only?",
      "doc_b_answer": "The dataset is based on faces and annotations of public figures (celebrities), which may introduce demographic biases. The old-male group shows the highest FPR, suggesting potential bias in how the model performs across different demographic segments.",
      "doc_b_visual_anchor": "Green dot at old-male row positioned at approximately 0.08 on x-axis",
      "doc_b_text_evidence": "Faces and annotations based on public figures (celebrities). No new information is inferred or annotated.",
      "doc_b_figure_id": "1810.03993_fig_1",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1810.03993/1810.03993/hybrid_auto/images/1810.03993_page0_fig0.jpg",
      "doc_b_caption": "",
      "doc_b_visual_score": 2,
      "score": 7.0
    },
    {
      "doc_a": "1602.05352",
      "doc_b": "1706.02409",
      "shared_entity_count": 2,
      "shared_entities": [
        "accuracy",
        "mse"
      ],
      "doc_a_query_id": "l1_1602.05352_1602.05352_fig_5_88",
      "doc_a_query": "Why does the blue MF-IPS curve achieve lower MSE than red MF-Naive across all alpha values?",
      "doc_a_answer": "MF-IPS uses propensity weighting to correct for selection bias, while MF-Naive does not account for biased observations. This allows MF-IPS to achieve better prediction accuracy through improved risk estimation.",
      "doc_a_visual_anchor": "blue MF-IPS curve consistently below red MF-Naive curve across alpha from 0 to 1",
      "doc_a_text_evidence": "Using the same semi-synthetic ML100K dataset and observation model as above, we compare our matrix factorization MF-IPS with the traditional unweighted matrix factorization MF-Naive.",
      "doc_a_figure_id": "1602.05352_fig_5",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1602.05352/1602.05352/hybrid_auto/images/1602.05352_page0_fig4.jpg",
      "doc_a_caption": "Figure 3. Prediction error (MSE) of matrix factorization methods as the observed ratings exhibit varying degrees of selection bias (left) and as propensity estimation quality degrades (right).",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1706.02409_1706.02409_fig_4_231",
      "doc_b_query": "Does the purple Hybrid separate curve dropping sharply near zero fairness loss support qualitative cross-dataset comparison?",
      "doc_b_answer": "Yes, the sharp drop demonstrates that in some datasets the fairness penalty can be substantially decreased with little cost to accuracy, enabling qualitative comparisons across datasets.",
      "doc_b_visual_anchor": "purple curve (Hybrid, separate) showing sharp drop from MSE ~0.17 to ~0.15 near fairness loss = 0",
      "doc_b_text_evidence": "The efficient fairness/accuracy frontiers pictured in Figure 1 can be compared across data sets in a qualitative sense — e.g. to see that in some datasets, the fairness penalty can be substantially decreased with little cost to accuracy.",
      "doc_b_figure_id": "1706.02409_fig_4",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1706.02409/1706.02409/hybrid_auto/images/1706.02409_page0_fig3.jpg",
      "doc_b_caption": "Figure 1: Efficient frontiers of accuracy vs. fairness for each dataset. For datasets with binary-valued targets (logistic regression), we consider three fairness notions (group, individual and hybrid), and for each examine building a single model or separate models for each group, yielding a total of six curves. For real-valued targets (linear regression), we consider two fairness notions (group and individual), and again single or separate models, yielding a total of four curves.",
      "doc_b_visual_score": 2,
      "score": 6.5
    },
    {
      "doc_a": "1607.06520",
      "doc_b": "1811.00103",
      "shared_entity_count": 1,
      "shared_entities": [
        "pca"
      ],
      "doc_a_query_id": "l1_1607.06520_1607.06520_fig_4_121",
      "doc_a_query": "Why would words above the horizontal red dashed line collapse to the vertical line after applying the debiasing algorithm?",
      "doc_a_answer": "The hard debiasing algorithm removes gender pair associations for gender neutral words, which are positioned above the horizontal line. Collapsing them to the vertical line eliminates their projection along the he-she axis while preserving gender neutrality.",
      "doc_a_visual_anchor": "horizontal red dashed line with words like 'homemaker', 'feminist', 'actresses' above it",
      "doc_a_text_evidence": "Our hard debiasing algorithm removes the gender pair associations for gender neutral words. In this figure, the words above the horizontal line would all be collapsed to the vertical line.",
      "doc_a_figure_id": "1607.06520_fig_4",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1607.06520/1607.06520/hybrid_auto/images/1607.06520_page0_fig3.jpg",
      "doc_a_caption": "Figure 7: Selected words projected along two axes: $x$ is a projection onto the difference between the embeddings of the words he and she, and $y$ is a direction learned in the embedding that captures gender neutrality, with gender neutral words above the line and gender specific words below the line. Our hard debiasing algorithm removes the gender pair associations for gender neutral words. In this figure, the words above the horizontal line would all be collapsed to the vertical line.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1811.00103_1811.00103_fig_6_648",
      "doc_b_query": "Does the convergence of all four lines to approximately 12 at 20 features support the claim that Fair PCA assigns equal loss across populations?",
      "doc_b_answer": "Yes, the convergence demonstrates that with sufficient features, Fair PCA achieves near-equal reconstruction error across Male and Female groups, consistent with optimal fairness solutions that minimize loss disparity between groups.",
      "doc_b_visual_anchor": "convergence of purple, blue, green, and red lines to ~12 at x=20",
      "doc_b_text_evidence": "Figure 3 shows the average reconstruction error of each population (Male/Female, Higher/Lower education) as the result of running vanilla PCA and Fair PCA on LFW and Credit data",
      "doc_b_figure_id": "1811.00103_fig_6",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1811.00103/1811.00103/hybrid_auto/images/1811.00103_page0_fig5.jpg",
      "doc_b_caption": "Figure 3: Reconstruction error of PCA/Fair PCA on LFW and the Default Credit data set.",
      "doc_b_visual_score": 4,
      "score": 6.5
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "1809.02244",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_b_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_b_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_b_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_b_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_b_figure_id": "1809.02244_fig_4",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_b_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_b_visual_score": 4,
      "score": 6.5
    },
    {
      "doc_a": "1705.10378",
      "doc_b": "1907.06430",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_a_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_a_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_a_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_a_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_a_figure_id": "1705.10378_fig_1",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1907.06430_1907.06430_fig_11_860",
      "doc_b_query": "Does the red solid arrow from A to Y represent the direct path whose unfairness is quantified by path-specific effect?",
      "doc_b_answer": "Yes, the red solid arrow from A to Y represents the direct path A → Y, whose unfairness is quantified by the path-specific effect PSE^aa when the path A → D → Y is considered fair.",
      "doc_b_visual_anchor": "red solid arrow from node A to node Y",
      "doc_b_text_evidence": "in which the path $A $ $D  Y$ is considered fair, unfairness can instead be quantified with the path-specific effect along the direct path $A  Y$ , PSE $^ { a a }$",
      "doc_b_figure_id": "1907.06430_fig_11",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1907.06430/1907.06430/hybrid_auto/images/1907.06430_page0_fig10.jpg",
      "doc_b_caption": "Fig. 7. CBN underlying a college admission scenario.",
      "doc_b_visual_score": 4,
      "score": 6.5
    },
    {
      "doc_a": "1809.02244",
      "doc_b": "2005.07293",
      "shared_entity_count": 1,
      "shared_entities": [
        "compas"
      ],
      "doc_a_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_a_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_a_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_a_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_a_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_a_figure_id": "1809.02244_fig_4",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_a_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_2005.07293_2005.07293_fig_3_909",
      "doc_b_query": "Do the near-flat red and green lines at 84% across all beta values support consistent performance across random splits?",
      "doc_b_answer": "Yes, the flat Parity and Classifier lines demonstrate consistent performance. Each point represents the average value of 10 experiments performed on the same 10 random splits across different beta values, ensuring robustness.",
      "doc_b_visual_anchor": "Red line with X markers and green line with triangle markers both maintaining approximately 84-85% accuracy from beta=0 to beta=0.9",
      "doc_b_text_evidence": "Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different beta values.",
      "doc_b_figure_id": "2005.07293_fig_3",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig2.jpg",
      "doc_b_caption": "Figure 2: Accuracy and fairness gain results for the COMPAS and Adult datasets over different $\\beta$ values. Top plots report the accuracy results, while bottom plots report the fairness gain results. Each point on the plots is the average value of 10 experiments performed on the 10 random splits. Notice that the 10 random split sets are the same across different $\\beta$ values. For details of these values along with standard deviation numbers refer to Tables 7 and 8 in the Appendixes section.",
      "doc_b_visual_score": 3,
      "score": 6.5
    },
    {
      "doc_a": "1703.06856",
      "doc_b": "1809.02244",
      "shared_entity_count": 1,
      "shared_entities": [
        "dag"
      ],
      "doc_a_query_id": "l1_1703.06856_1703.06856_fig_9_223",
      "doc_a_query": "How does the fourth plot's increased red dot density in the yellow-circled region demonstrate racial effects on arrest outcomes?",
      "doc_a_answer": "The fourth plot shows the counterfactual where everyone is treated as Black Hispanic, resulting in more arrests (red dots) compared to other scenarios, demonstrating that race significantly affects arrest likelihood in the model.",
      "doc_a_visual_anchor": "Fourth plot 'Arrest if Black Hispanic (counterfactual)' showing higher concentration of red dots in yellow-circled northern region",
      "doc_a_text_evidence": "Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_figure_id": "1703.06856_fig_9",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1703.06856/1703.06856/hybrid_auto/images/1703.06856_page0_fig8.jpg",
      "doc_a_caption": "Figure 4: How race affects arrest. The above maps show how altering one’s race affects whether or not they will be arrested, according to the model. The left-most plot shows the distribution of White and Black Hispanic populations in the stop-and-frisk dataset. The second plot shows the true arrests for all of the stops. Given our model we can compute whether or not every individual in the dataset would be arrest had they been white. We show this counterfactual in the third plot. Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1809.02244_1809.02244_fig_4_530",
      "doc_b_query": "How do the dashed and dotted blue curves demonstrate the formalization extended from Nabi and Shpitser 2018 for utility parameter above 2.5?",
      "doc_b_answer": "The gap between the dashed (optimal unrestricted) and dotted (optimal fair) blue curves shows the tradeoff between unconstrained policy optimization and fairness-constrained policy learning, illustrating how fairness constraints modify decision-making to induce more equitable outcomes.",
      "doc_b_visual_anchor": "Separation between blue dashed line (~1.0) and blue dotted line (~0.8) for utility parameter values above 2.5",
      "doc_b_text_evidence": "We have extended a formalization of algorithmic fairness from Nabi & Shpitser (2018) to the setting of learning optimal policies under fairness constraints. We show how to constrain a set of statistical models and learn a policy such that subsequent decision making given new observations from the \"unfair world\" induces high-quality outcomes while satisfying the specified fairness constraints",
      "doc_b_figure_id": "1809.02244_fig_4",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.02244/1809.02244/hybrid_auto/images/1809.02244_page0_fig3.jpg",
      "doc_b_caption": "Figure 2. Group-level incarceration rates for the COMPAS data as a function of the utility parameter $\\theta$ .",
      "doc_b_visual_score": 4,
      "score": 6.5
    },
    {
      "doc_a": "1705.10378",
      "doc_b": "1802.08139",
      "shared_entity_count": 1,
      "shared_entities": [
        "uci"
      ],
      "doc_a_query_id": "l1_1705.10378_1705.10378_fig_1_225",
      "doc_a_query": "Does the path A→Y represent a direct causal pathway distinct from the A→M→Y mediated pathway?",
      "doc_a_answer": "Yes, the direct arrow A→Y represents one causal pathway, while A→M→Y represents a mediated pathway through M, allowing decomposition of effects along particular causal pathways.",
      "doc_a_visual_anchor": "Blue arrow directly connecting node A to node Y, bypassing node M",
      "doc_a_text_evidence": "we may wish to decompose the effect of $A$ on $Y$ into the contribution of the path $A  W  Y$ , and the path bundle $A  Y$ and $A \\to M \\to W \\to Y .$",
      "doc_a_figure_id": "1705.10378_fig_1",
      "doc_a_figure_type": "diagram",
      "doc_a_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg",
      "doc_a_caption": "Figure 1: (a) A causal graph with a single mediator. (b) A causal graph with two mediators, one confounded with the outcome via an unobserved common cause. (c) A causal graph with a single mediator where the natural direct effect is not identified.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1802.08139_1802.08139_fig_17_356",
      "doc_b_query": "Why does the gray node C in subfigure (a) become a red bidirected link in the ADMG representation?",
      "doc_b_answer": "The gray node C represents an unobserved confounder. In ADMG notation, unobserved common causes are indicated by red bidirected links between the affected variables, which is why C's influence is shown as a red bidirected edge in subfigure (b).",
      "doc_b_visual_anchor": "Gray node C in subfigure (a) and red bidirected edge in subfigure (b)",
      "doc_b_text_evidence": "An ADMG is a causal graph containing two kinds of links, directed links (either green or black depending on whether we are interested in the corresponding causal path), and red bidirected links, indicating the presence of an unobserved common cause.",
      "doc_b_figure_id": "1802.08139_fig_17",
      "doc_b_figure_type": "diagram",
      "doc_b_image_path": "data/mineru_output/1802.08139/1802.08139/hybrid_auto/images/1802.08139_page0_fig16.jpg",
      "doc_b_caption": "Figure 7. (a): GCM with an unobserved confounder $C$ indicated with a gray node. (b): ADMG corresponding to (a). The causal effect along the green path $A  Y$ cannot be identified by only using observed variables.",
      "doc_b_visual_score": 4,
      "score": 6.5
    },
    {
      "doc_a": "1511.00830",
      "doc_b": "1809.10083",
      "shared_entity_count": 1,
      "shared_entities": [
        "sne"
      ],
      "doc_a_query_id": "l1_1511.00830_1511.00830_fig_13_73",
      "doc_a_query": "Why do the blue and red points heavily overlap in this visualization, given the model uses both s and MMD?",
      "doc_a_answer": "The model successfully factors out domain (gender) information by incorporating both the sensitive attribute s and MMD regularization, resulting in representations where male and female samples are not separable and cluster together, demonstrating fairness through indistinguishability.",
      "doc_a_visual_anchor": "overlapping blue (male) and red (female) scattered point clusters",
      "doc_a_text_evidence": "Our model was successful in factoring out the domain information, since the accuracy, measured both linearly (LR) and non-linearly (RF), was towards random chance",
      "doc_a_figure_id": "1511.00830_fig_13",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig12.jpg",
      "doc_a_caption": "Figure 4: t-SNE (van der Maaten, 2013) visualizations from the Adult dataset on: (a): original x , (b): latent $\\mathbf { z } _ { 1 }$ without s and MMD, (c): latent $\\mathbf { z } _ { 1 }$ with s and without MMD, (d): latent $\\mathbf { z } _ { 1 }$ with s and MMD. Blue colour corresponds to males whereas red colour corresponds to females.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1809.10083_1809.10083_fig_16_555",
      "doc_b_query": "Why does the blue cluster at x=-45.0 show tighter grouping than the red cluster at x=45.0 in this embedding?",
      "doc_b_answer": "The visualization shows e₁ labeled by subject-ID with numerical markers. The tighter blue clustering likely reflects better subject-ID separation in this region of the embedding space compared to the more dispersed red region.",
      "doc_b_visual_anchor": "Blue cluster at x=-45.0 versus red cluster at x=45.0",
      "doc_b_text_evidence": "Figure 2 shows t-SNE [15] visualization of raw data and embeddings e₁ and e₂ for our model.",
      "doc_b_figure_id": "1809.10083_fig_16",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1809.10083/1809.10083/hybrid_auto/images/1809.10083_page0_fig15.jpg",
      "doc_b_caption": "Table 2: Results on Chairs. High $A _ { y }$ and low $A _ { z }$ are desired.   ",
      "doc_b_visual_score": 3,
      "score": 6.0
    },
    {
      "doc_a": "1703.06856",
      "doc_b": "1805.03094",
      "shared_entity_count": 1,
      "shared_entities": [
        "map"
      ],
      "doc_a_query_id": "l1_1703.06856_1703.06856_fig_9_223",
      "doc_a_query": "How does the fourth plot's increased red dot density in the yellow-circled region demonstrate racial effects on arrest outcomes?",
      "doc_a_answer": "The fourth plot shows the counterfactual where everyone is treated as Black Hispanic, resulting in more arrests (red dots) compared to other scenarios, demonstrating that race significantly affects arrest likelihood in the model.",
      "doc_a_visual_anchor": "Fourth plot 'Arrest if Black Hispanic (counterfactual)' showing higher concentration of red dots in yellow-circled northern region",
      "doc_a_text_evidence": "Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_figure_id": "1703.06856_fig_9",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1703.06856/1703.06856/hybrid_auto/images/1703.06856_page0_fig8.jpg",
      "doc_a_caption": "Figure 4: How race affects arrest. The above maps show how altering one’s race affects whether or not they will be arrested, according to the model. The left-most plot shows the distribution of White and Black Hispanic populations in the stop-and-frisk dataset. The second plot shows the true arrests for all of the stops. Given our model we can compute whether or not every individual in the dataset would be arrest had they been white. We show this counterfactual in the third plot. Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1805.03094_1805.03094_fig_2_397",
      "doc_b_query": "Why does the red topmost curve maintain acceptance probability near 0.45 while blue drops below 0.25 across answer positions?",
      "doc_b_answer": "The horizontal bands correspond to different subgroups conditioned on total number of answers the user has written, showing performance variation across experience levels as answer position increases.",
      "doc_b_visual_anchor": "red topmost curve at ~0.45 probability versus blue bottom curve at ~0.25 probability",
      "doc_b_text_evidence": "the horizontal bands corresponding to the different subgroups, conditioned on total number of answers the user has written",
      "doc_b_figure_id": "1805.03094_fig_2",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1805.03094/1805.03094/hybrid_auto/images/1805.03094_page0_fig1.jpg",
      "doc_b_caption": "Figure 1: Disaggregation of Stack Exchange data. (a) The heat map shows the probability the answer is accepted as a function of its answer position within a session, with the horizontal bands corresponding to the different subgroups, conditioned on total number of answers the user has written. (b) Number of data samples within each bin of the heat map. Note that the outcome becomes noisy when there are few samples. The trends in performance as a function of answer position in (c) disaggregated data and (d) aggregate data. Error bars in (c) and (d) show $9 5 \\%$ confidence interval.",
      "doc_b_visual_score": 3,
      "score": 6.0
    },
    {
      "doc_a": "1811.00103",
      "doc_b": "1904.03310",
      "shared_entity_count": 1,
      "shared_entities": [
        "pca"
      ],
      "doc_a_query_id": "l1_1811.00103_1811.00103_fig_6_648",
      "doc_a_query": "Does the convergence of all four lines to approximately 12 at 20 features support the claim that Fair PCA assigns equal loss across populations?",
      "doc_a_answer": "Yes, the convergence demonstrates that with sufficient features, Fair PCA achieves near-equal reconstruction error across Male and Female groups, consistent with optimal fairness solutions that minimize loss disparity between groups.",
      "doc_a_visual_anchor": "convergence of purple, blue, green, and red lines to ~12 at x=20",
      "doc_a_text_evidence": "Figure 3 shows the average reconstruction error of each population (Male/Female, Higher/Lower education) as the result of running vanilla PCA and Fair PCA on LFW and Credit data",
      "doc_a_figure_id": "1811.00103_fig_6",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1811.00103/1811.00103/hybrid_auto/images/1811.00103_page0_fig5.jpg",
      "doc_a_caption": "Figure 3: Reconstruction error of PCA/Fair PCA on LFW and the Default Credit data set.",
      "doc_a_visual_score": 4,
      "doc_b_query_id": "l1_1904.03310_1904.03310_fig_1_782",
      "doc_b_query": "Why do the first two bars at positions 0 and 1 reach 0.27 and 0.22 instead of one dominant component?",
      "doc_b_answer": "ELMo has two principal components for gender, unlike GloVe which has only one. This explains why the first two bars show comparable variance levels rather than a single dominant component.",
      "doc_b_visual_anchor": "First bar at position 0 (0.27) and second bar at position 1 (0.22)",
      "doc_b_text_evidence": "Figure 1 shows there are two principal components for gender in ELMo, in contrast to GloVe which only has one (Bolukbasi et al., 2016).",
      "doc_b_figure_id": "1904.03310_fig_1",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1904.03310/1904.03310/hybrid_auto/images/1904.03310_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: Left: Percentage of explained variance in PCA in the embedding differences. Right: Selected words projecting to the first two principle components where the blue dots are the sentences with male context and the orange dots are from the sentences with female context.",
      "doc_b_visual_score": 1,
      "score": 5.5
    },
    {
      "doc_a": "1608.07187",
      "doc_b": "1703.06856",
      "shared_entity_count": 1,
      "shared_entities": [
        "map"
      ],
      "doc_a_query_id": "l1_1608.07187_1608.07187_fig_3_131",
      "doc_a_query": "Does the heir-heiress vector relationship at horizontal position 0.1 exemplify the semantic relationships captured alongside countries-capitals and companies-CEOs?",
      "doc_a_answer": "Yes, the heir-heiress pair demonstrates the same type of algebraic vector relationship shown for gender pairs, which is analogous to other semantic relationships like countries and capitals or companies and CEOs mentioned in the methodology.",
      "doc_a_visual_anchor": "Dashed line connecting heir (y≈0.03) to heiress (y≈0.5) at horizontal position around 0.1",
      "doc_a_text_evidence": "Similar algebraic relationships have been shown for other semantic relationships, such as countries and their capital cities, companies and their CEOs, or simply different forms of the same word.",
      "doc_a_figure_id": "1608.07187_fig_3",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1608.07187/1608.07187/hybrid_auto/images/1608.07187_page0_fig2.jpg",
      "doc_a_caption": "Figure 3. A 2D projection (first two principal components) of the 300-dimensional vector space of the GloVe word embedding (Pennington et al., 2014). The lines illustrate algebraic relationships between related words: pairs of words that differ only by gender map to pairs of vectors whose vector difference is roughly constant. Similar algebraic relationships have been shown for other semantic relationships, such as countries and their capital cities, companies and their CEOs, or simply different forms of the same word.",
      "doc_a_visual_score": 2,
      "doc_b_query_id": "l1_1703.06856_1703.06856_fig_9_223",
      "doc_b_query": "How does the fourth plot's increased red dot density in the yellow-circled region demonstrate racial effects on arrest outcomes?",
      "doc_b_answer": "The fourth plot shows the counterfactual where everyone is treated as Black Hispanic, resulting in more arrests (red dots) compared to other scenarios, demonstrating that race significantly affects arrest likelihood in the model.",
      "doc_b_visual_anchor": "Fourth plot 'Arrest if Black Hispanic (counterfactual)' showing higher concentration of red dots in yellow-circled northern region",
      "doc_b_text_evidence": "Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_b_figure_id": "1703.06856_fig_9",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1703.06856/1703.06856/hybrid_auto/images/1703.06856_page0_fig8.jpg",
      "doc_b_caption": "Figure 4: How race affects arrest. The above maps show how altering one’s race affects whether or not they will be arrested, according to the model. The left-most plot shows the distribution of White and Black Hispanic populations in the stop-and-frisk dataset. The second plot shows the true arrests for all of the stops. Given our model we can compute whether or not every individual in the dataset would be arrest had they been white. We show this counterfactual in the third plot. Similarly, we can compute this counterfactual if everyone had been Black Hispanic, as shown in the fourth plot.",
      "doc_b_visual_score": 3,
      "score": 5.5
    },
    {
      "doc_a": "1608.07187",
      "doc_b": "1805.03094",
      "shared_entity_count": 1,
      "shared_entities": [
        "map"
      ],
      "doc_a_query_id": "l1_1608.07187_1608.07187_fig_3_131",
      "doc_a_query": "Does the heir-heiress vector relationship at horizontal position 0.1 exemplify the semantic relationships captured alongside countries-capitals and companies-CEOs?",
      "doc_a_answer": "Yes, the heir-heiress pair demonstrates the same type of algebraic vector relationship shown for gender pairs, which is analogous to other semantic relationships like countries and capitals or companies and CEOs mentioned in the methodology.",
      "doc_a_visual_anchor": "Dashed line connecting heir (y≈0.03) to heiress (y≈0.5) at horizontal position around 0.1",
      "doc_a_text_evidence": "Similar algebraic relationships have been shown for other semantic relationships, such as countries and their capital cities, companies and their CEOs, or simply different forms of the same word.",
      "doc_a_figure_id": "1608.07187_fig_3",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1608.07187/1608.07187/hybrid_auto/images/1608.07187_page0_fig2.jpg",
      "doc_a_caption": "Figure 3. A 2D projection (first two principal components) of the 300-dimensional vector space of the GloVe word embedding (Pennington et al., 2014). The lines illustrate algebraic relationships between related words: pairs of words that differ only by gender map to pairs of vectors whose vector difference is roughly constant. Similar algebraic relationships have been shown for other semantic relationships, such as countries and their capital cities, companies and their CEOs, or simply different forms of the same word.",
      "doc_a_visual_score": 2,
      "doc_b_query_id": "l1_1805.03094_1805.03094_fig_2_397",
      "doc_b_query": "Why does the red topmost curve maintain acceptance probability near 0.45 while blue drops below 0.25 across answer positions?",
      "doc_b_answer": "The horizontal bands correspond to different subgroups conditioned on total number of answers the user has written, showing performance variation across experience levels as answer position increases.",
      "doc_b_visual_anchor": "red topmost curve at ~0.45 probability versus blue bottom curve at ~0.25 probability",
      "doc_b_text_evidence": "the horizontal bands corresponding to the different subgroups, conditioned on total number of answers the user has written",
      "doc_b_figure_id": "1805.03094_fig_2",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1805.03094/1805.03094/hybrid_auto/images/1805.03094_page0_fig1.jpg",
      "doc_b_caption": "Figure 1: Disaggregation of Stack Exchange data. (a) The heat map shows the probability the answer is accepted as a function of its answer position within a session, with the horizontal bands corresponding to the different subgroups, conditioned on total number of answers the user has written. (b) Number of data samples within each bin of the heat map. Note that the outcome becomes noisy when there are few samples. The trends in performance as a function of answer position in (c) disaggregated data and (d) aggregate data. Error bars in (c) and (d) show $9 5 \\%$ confidence interval.",
      "doc_b_visual_score": 3,
      "score": 5.5
    },
    {
      "doc_a": "1610.07524",
      "doc_b": "1810.03993",
      "shared_entity_count": 1,
      "shared_entities": [
        "fpr"
      ],
      "doc_a_query_id": "l1_1610.07524_1610.07524_fig_2_170",
      "doc_a_query": "Why do differences persist between gray and orange bars within each prior category despite equal overall FPR claims?",
      "doc_a_answer": "Even if overall FPR is equal between Black and White defendants, differences in error rates can still appear within individual prior record score categories. This explains the persistent gap between gray and orange bars across all five groupings shown.",
      "doc_a_visual_anchor": "Consistent separation between gray and orange bars across all five x-axis categories (0, 1-3, 4-6, 7-10, >10)",
      "doc_a_text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2).",
      "doc_a_figure_id": "1610.07524_fig_2",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg",
      "doc_a_caption": "Figure 2: False positive rates across prior record count for defendants charged with a Misdemeanor offense. Plot is based on assessing a defendant as “high-risk” if their COMPAS decile score is $> 4$ . Error bars represent 95% confidence intervals.   ",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1810.03993_1810.03993_fig_1_622",
      "doc_b_query": "Why does old-male reach the highest false positive rate near 0.08 when analyzing public figures only?",
      "doc_b_answer": "The dataset is based on faces and annotations of public figures (celebrities), which may introduce demographic biases. The old-male group shows the highest FPR, suggesting potential bias in how the model performs across different demographic segments.",
      "doc_b_visual_anchor": "Green dot at old-male row positioned at approximately 0.08 on x-axis",
      "doc_b_text_evidence": "Faces and annotations based on public figures (celebrities). No new information is inferred or annotated.",
      "doc_b_figure_id": "1810.03993_fig_1",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1810.03993/1810.03993/hybrid_auto/images/1810.03993_page0_fig0.jpg",
      "doc_b_caption": "",
      "doc_b_visual_score": 2,
      "score": 5.5
    },
    {
      "doc_a": "1607.06520",
      "doc_b": "1904.03310",
      "shared_entity_count": 1,
      "shared_entities": [
        "pca"
      ],
      "doc_a_query_id": "l1_1607.06520_1607.06520_fig_4_121",
      "doc_a_query": "Why would words above the horizontal red dashed line collapse to the vertical line after applying the debiasing algorithm?",
      "doc_a_answer": "The hard debiasing algorithm removes gender pair associations for gender neutral words, which are positioned above the horizontal line. Collapsing them to the vertical line eliminates their projection along the he-she axis while preserving gender neutrality.",
      "doc_a_visual_anchor": "horizontal red dashed line with words like 'homemaker', 'feminist', 'actresses' above it",
      "doc_a_text_evidence": "Our hard debiasing algorithm removes the gender pair associations for gender neutral words. In this figure, the words above the horizontal line would all be collapsed to the vertical line.",
      "doc_a_figure_id": "1607.06520_fig_4",
      "doc_a_figure_type": "plot",
      "doc_a_image_path": "data/mineru_output/1607.06520/1607.06520/hybrid_auto/images/1607.06520_page0_fig3.jpg",
      "doc_a_caption": "Figure 7: Selected words projected along two axes: $x$ is a projection onto the difference between the embeddings of the words he and she, and $y$ is a direction learned in the embedding that captures gender neutrality, with gender neutral words above the line and gender specific words below the line. Our hard debiasing algorithm removes the gender pair associations for gender neutral words. In this figure, the words above the horizontal line would all be collapsed to the vertical line.",
      "doc_a_visual_score": 3,
      "doc_b_query_id": "l1_1904.03310_1904.03310_fig_1_782",
      "doc_b_query": "Why do the first two bars at positions 0 and 1 reach 0.27 and 0.22 instead of one dominant component?",
      "doc_b_answer": "ELMo has two principal components for gender, unlike GloVe which has only one. This explains why the first two bars show comparable variance levels rather than a single dominant component.",
      "doc_b_visual_anchor": "First bar at position 0 (0.27) and second bar at position 1 (0.22)",
      "doc_b_text_evidence": "Figure 1 shows there are two principal components for gender in ELMo, in contrast to GloVe which only has one (Bolukbasi et al., 2016).",
      "doc_b_figure_id": "1904.03310_fig_1",
      "doc_b_figure_type": "plot",
      "doc_b_image_path": "data/mineru_output/1904.03310/1904.03310/hybrid_auto/images/1904.03310_page0_fig0.jpg",
      "doc_b_caption": "Figure 1: Left: Percentage of explained variance in PCA in the embedding differences. Right: Selected words projecting to the first two principle components where the blue dots are the sentences with male context and the orange dots are from the sentences with female context.",
      "doc_b_visual_score": 1,
      "score": 5.0
    }
  ]
}