{"query": "How does the fairness-utility tradeoff for logistic regression on German Credit differ between the combinatorial repair approach and the optimized pre-processing method at disparate impact 0.8?", "answer": "The combinatorial repair approach shows logistic regression achieving utility around 0.65-0.70 at DI=0.8 on German Credit with a clear downward trend. In contrast, optimized pre-processing with logistic regression maintains higher balanced accuracy (approximately 0.73-0.75) at similar disparate impact levels near 0.8, demonstrating superior preservation of utility while achieving comparable fairness.", "query_type": "cross_comparison", "turns": ["How does the fairness-utility tradeoff for logistic regression on German Credit differ between the combinatorial repair approach and the optimized pre-processing method at disparate impact 0.8?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Scatter points with dashed trend line in German Credit panel showing utility decline from ~0.7 to ~0.55 as DI approaches 0.8", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases."}, {"doc_id": "1810.01943", "anchor": "Orange circles (LR,Optimized pre-processing) positioned at disparate impact ~0.75-0.8 in top panel with balanced accuracy ~0.73-0.75", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0. The circles indicate the mean value"}], "pair": {"doc_a": "1412.3756", "doc_b": "1810.01943"}, "shared_entities": ["DI", "Disparate impact", "Fairness", "German Credit", "LR", "Logistic regression", "accuracy", "disparate impact", "logistic regression"], "pair_score": 35.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Can the attention mechanism in the general classification model explain how optimized pre-processing achieves better disparate impact scores near 0.8 compared to equal odds postprocessing?", "answer": "The attention layer produces weighted feature representations that could enable optimized pre-processing to learn fairer embeddings upstream, achieving disparate impact values closer to the ideal value of 1 (as shown by green circles at ~0.8). In contrast, equal odds postprocessing operates on final predictions without modifying the learned feature representations, resulting in disparate impact values further from 1 in the fairness-accuracy tradeoff.", "query_type": "cross_synthesis", "turns": ["Can the attention mechanism in the general classification model explain how optimized pre-processing achieves better disparate impact scores near 0.8 compared to equal odds postprocessing?"], "evidence_refs": [{"doc_id": "1810.01943", "anchor": "green circles (RF,Optimized pre-processing) at disparate impact ~0.8 in top panel versus red/pink circles (Equal odds postprocessing) at disparate impact ~0.7", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0."}, {"doc_id": "2109.03952", "anchor": "orange Attention layer positioned between red embedding boxes (e1, e2, ..., en) and yellow Dense Layer boxes", "text_evidence": "This is passed to the attention layer which produces a d^e - dimensional vector representation for the sample instance i which is passed to two dense layers to get the final classification output."}], "pair": {"doc_a": "1810.01943", "doc_b": "2109.03952"}, "shared_entities": ["Accuracy", "Parity", "SPD", "Statistical Parity Difference", "accuracy", "parity"], "pair_score": 21.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg", "doc_a_figure_id": "1810.01943_fig_10", "doc_b_figure_id": "2109.03952_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Does the spatial separation of lighting conditions in Extended Yale-B t-SNE embeddings align with the unsupervised model's assumption that nuisance variables directly affect observed data?", "answer": "Yes, the clear spatial clustering by lighting condition (orange lower-right vs cyan upper-right markers) in the t-SNE visualization demonstrates that lighting acts as a nuisance variable directly affecting observed face images, consistent with the S→X pathway in the unsupervised model where noise variables directly influence data X independent of informative latent factors Z.", "query_type": "cross_synthesis", "turns": ["Does the spatial separation of lighting conditions in Extended Yale-B t-SNE embeddings align with the unsupervised model's assumption that nuisance variables directly affect observed data?"], "evidence_refs": [{"doc_id": "1511.00830", "anchor": "arrow from node S directly to node X, bypassing node Z", "text_evidence": "Uninformative dimensions are often called \"noise\" or \"nuisance variables\" while informative dimensions are usually called latent or hidden factors of variation."}, {"doc_id": "1809.10083", "anchor": "orange plus signs (lower-right) and cyan stars (upper-right) spatially separated in t-SNE plot", "text_evidence": "Figure 2 shows t-SNE [15] visualization of raw data and embeddings $e _ { 1 }$ and $e _ { 2 }$ for our model."}], "pair": {"doc_a": "1511.00830", "doc_b": "1809.10083"}, "shared_entities": ["Extended Yale", "ID", "SNE", "t-SNE"], "pair_score": 18.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1809.10083/1809.10083/hybrid_auto/images/1809.10083_page0_fig4.jpg", "doc_a_figure_id": "1511.00830_fig_1", "doc_b_figure_id": "1809.10083_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "Can attention-weighted feature embeddings from the general classification model help satisfy equal-cost constraints between calibrated classifier sets H₁* and H₂* on the Pareto frontier?", "answer": "The calibrated classifier sets H₁* and H₂* lie on the black diagonal Pareto frontier representing optimal false-positive/false-negative tradeoffs for each group. The attention layer produces weighted d^e-dimensional representations from feature embeddings, which could potentially be optimized to help both groups achieve equal-cost points along their respective calibrated frontiers, though this requires coordinating the attention mechanism with group-specific fairness constraints.", "query_type": "cross_synthesis", "turns": ["Can attention-weighted feature embeddings from the general classification model help satisfy equal-cost constraints between calibrated classifier sets H₁* and H₂* on the Pareto frontier?"], "evidence_refs": [{"doc_id": "1709.02012", "anchor": "black diagonal boundary line with H₁* and H₂* calibrated classifier sets", "text_evidence": "H₁*, H₂* are the set of cal. classifiers for the two groups"}, {"doc_id": "2109.03952", "anchor": "orange Attention layer box between feature embeddings and dense layers", "text_evidence": "attention layer which produces a d^e-dimensional vector representation for the sample instance"}], "pair": {"doc_a": "1709.02012", "doc_b": "2109.03952"}, "shared_entities": ["Equalized Odds", "Parity", "parity"], "pair_score": 16.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1709.02012/1709.02012/hybrid_auto/images/1709.02012_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg", "doc_a_figure_id": "1709.02012_fig_3", "doc_b_figure_id": "2109.03952_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does the direct S→X connection in the unsupervised model relate to removing digit class information when generating stylistically similar MNIST digits across different labels?", "answer": "The direct S→X arrow models nuisance variables that affect observed data independent of informative latent factors Z, representing uninformative dimensions. Similarly, when digit label serves as covariate c in MNIST generation, non-class stylistic information is pushed into latent space while removing exact digit information, allowing style extraction from one digit (e.g., real 9) to generate all ten digits by recombining with any specified label c′.", "query_type": "cross_synthesis", "turns": ["How does the direct S→X connection in the unsupervised model relate to removing digit class information when generating stylistically similar MNIST digits across different labels?"], "evidence_refs": [{"doc_id": "1511.00830", "anchor": "arrow from node S (top-left) directly to node X (bottom-center), bypassing Z", "text_evidence": "Uninformative dimensions are often called \"noise\" or \"nuisance variables\" while informative dimensions are usually called latent or hidden factors of variation."}, {"doc_id": "1805.09458", "anchor": "Top row showing real digit 9 on left generating sequence 0123456789 on right", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}], "pair": {"doc_a": "1511.00830", "doc_b": "1805.09458"}, "shared_entities": ["SNE", "VFAE", "accuracy", "t-SNE"], "pair_score": 15.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_a_figure_id": "1511.00830_fig_1", "doc_b_figure_id": "1805.09458_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "Can the attention layer's weighted feature combination mechanism be used to implement the equity-based resource distribution shown by the different-height boxes under each figure?", "answer": "Yes, the attention layer computes weights and produces weighted combinations of input feature embeddings, which could theoretically assign different weights (analogous to different box heights) to features representing different demographic groups. However, equity requires compensating historically disadvantaged groups with higher resource allocation, while standard attention mechanisms optimize for predictive accuracy without inherent fairness constraints.", "query_type": "cross_synthesis", "turns": ["Can the attention layer's weighted feature combination mechanism be used to implement the equity-based resource distribution shown by the different-height boxes under each figure?"], "evidence_refs": [{"doc_id": "2005.07293", "anchor": "Right panel 'Equity' showing different-height brown boxes (tallest under yellow figure, medium under purple, shortest under blue)", "text_evidence": "Equity is the distribution of resources among groups to overcome obstacles and to raise their opportunities for access. Thus, historically disadvantaged groups are compensated, and others get their fair share to reach their goals."}, {"doc_id": "2109.03952", "anchor": "Orange Attention layer box between red embedding boxes and yellow Dense Layer boxes", "text_evidence": "The Computation of attention weights and the final representation for a sample"}], "pair": {"doc_a": "2005.07293", "doc_b": "2109.03952"}, "shared_entities": ["Accuracy", "Parity", "accuracy", "parity"], "pair_score": 15.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg", "doc_a_figure_id": "2005.07293_fig_1", "doc_b_figure_id": "2109.03952_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Can the attention mechanism's weighted combination of feature embeddings be used to optimize the convex cost function defined by the horizontal gap in the ROC-based equalized odds framework?", "answer": "The attention layer produces a weighted representation from input embeddings that could theoretically parameterize threshold selection, but the ROC-based equalized odds optimization relies on a convex cost function proportional to the horizontal gap between the ROC curve and profit-maximizing tangent line, which is optimized via ternary search rather than learned attention weights. The attention mechanism learns feature importance for classification, while the ROC framework optimizes post-processing thresholds for fairness constraints.", "query_type": "cross_synthesis", "turns": ["Can the attention mechanism's weighted combination of feature embeddings be used to optimize the convex cost function defined by the horizontal gap in the ROC-based equalized odds framework?"], "evidence_refs": [{"doc_id": "1610.02413", "anchor": "Black arrow pointing to horizontal gap between blue ROC curve and tangent line in lower right", "text_evidence": "within each group the cost for a given true positive rate is proportional to the horizontal gap between the ROC curve and the profit-maximizing tangent line (i.e., the two curves on the left plot), so it is a convex function of the true positive rate"}, {"doc_id": "2109.03952", "anchor": "orange Attention layer box positioned between red embedding boxes (e1, e2, ..., en) and yellow Dense Layer boxes", "text_evidence": "This is passed to the attention layer which produces a d^e-dimensional vector representation for the sample instance i which is passed to two dense layers to get the final classification output"}], "pair": {"doc_a": "1610.02413", "doc_b": "2109.03952"}, "shared_entities": ["equalized odds", "parity"], "pair_score": 15.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1610.02413/1610.02413/hybrid_auto/images/1610.02413_page0_fig3.jpg", "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg", "doc_a_figure_id": "1610.02413_fig_4", "doc_b_figure_id": "2109.03952_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Does achieving disparate impact near 1.0 using optimized pre-processing align with the equality framework or the equity framework that provides different-height boxes?", "answer": "Optimized pre-processing achieves disparate impact near 1.0 (green circles at ~0.8 in top panel) by equalizing outcome distributions across groups, aligning with the equality framework where all groups receive identical resources (same-height boxes). This differs from the equity framework shown in the right panel, which provides compensatory resources (taller box for yellow figure) to overcome historical disadvantages rather than enforcing statistical parity.", "query_type": "cross_synthesis", "turns": ["Does achieving disparate impact near 1.0 using optimized pre-processing align with the equality framework or the equity framework that provides different-height boxes?"], "evidence_refs": [{"doc_id": "1810.01943", "anchor": "green circles (RF,Optimized pre-processing) at disparate impact ~0.8 in top panel", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0."}, {"doc_id": "2005.07293", "anchor": "Left panel 'Equality' with same-height boxes versus right panel 'Equity' with different-height boxes, tallest under yellow figure", "text_evidence": "Equity is the distribution of resources among groups to overcome obstacles and to raise their opportunities for access. Thus, historically disadvantaged groups are compensated, and others get their fair share to reach their goals."}], "pair": {"doc_a": "1810.01943", "doc_b": "2005.07293"}, "shared_entities": ["Accuracy", "Parity", "accuracy", "parity"], "pair_score": 14.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig0.jpg", "doc_a_figure_id": "1810.01943_fig_10", "doc_b_figure_id": "2005.07293_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Can the attention-based architecture with learned feature embeddings mitigate the accuracy-fairness tradeoff observed when varying λ in the Adult dataset MTL model?", "answer": "The MTL model on Adult dataset shows a fundamental tradeoff: increasing λ from 2e-10 to 1 drops ACC from ~91% to ~67% while EOd rises from ~0.05 to ~0.13. The attention-based architecture learns weighted feature representations through an attention layer that produces instance-specific embeddings, potentially enabling more nuanced fairness constraints. However, whether attention mechanisms can circumvent this inherent accuracy-EOd tension depends on whether the attention layer can identify and reweight discriminatory features without sacrificing predictive signal.", "query_type": "cross_synthesis", "turns": ["Can the attention-based architecture with learned feature embeddings mitigate the accuracy-fairness tradeoff observed when varying λ in the Adult dataset MTL model?"], "evidence_refs": [{"doc_id": "1810.08683", "anchor": "opposing trends in bottom panel: blue ACC declining from ~91 to ~67 and orange EOd rising from ~0.05 to ~0.13 as λ increases", "text_evidence": "This hypothesis is also supported by the results of Figure 5, in which we check how the accuracy and fairness, as measured with the EOd, varies by varying"}, {"doc_id": "2109.03952", "anchor": "orange Attention layer between red embedding boxes (e_k) and yellow Dense Layer boxes", "text_evidence": "These vectors are passed to the attention layer. The Computation of attention weights and the final representation for a sample is"}], "pair": {"doc_a": "1810.08683", "doc_b": "2109.03952"}, "shared_entities": ["accuracy", "equalized odds"], "pair_score": 14.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1810.08683/1810.08683/hybrid_auto/images/1810.08683_page0_fig3.jpg", "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg", "doc_a_figure_id": "1810.08683_fig_4", "doc_b_figure_id": "2109.03952_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does the utility-fairness tradeoff slope observed in the Adult Income repair process compare to the Price of Fairness pattern for separate model hybrid regularizers?", "answer": "The Adult Income combinatorial repair shows utility declining from ~0.75 to ~0.70 as disparate impact approaches 1.0, demonstrating a gradual tradeoff. In contrast, the hybrid separate model regularizers show Price of Fairness progressively increasing from ~1.0 to ~1.6 as alpha decreases from 0.5 to 0.01, indicating steeper performance costs under stronger fairness constraints. Both patterns confirm fairness-utility tradeoffs, but the regularization approach exhibits more pronounced performance degradation.", "query_type": "cross_comparison", "turns": ["How does the utility-fairness tradeoff slope observed in the Adult Income repair process compare to the Price of Fairness pattern for separate model hybrid regularizers?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Adult Income scatter points with dashed trend line showing utility decline from left to right as disparate impact increases toward DI=1.0", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases."}, {"doc_id": "1706.02409", "anchor": "magenta (Hybrid, separate) bars progressively increasing in height from ~1.0 to ~1.6 as alpha decreases from 0.5 to 0.01", "text_evidence": "As alpha decreases (stronger regularization), the hybrid fairness regularizers show increasing Price of Fairness, indicating that stricter hybrid fairness constraints progressively sacrifice more model performance to achieve fairness goals."}], "pair": {"doc_a": "1412.3756", "doc_b": "1706.02409"}, "shared_entities": ["Fairness", "accuracy", "logistic regression"], "pair_score": 13.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1706.02409/1706.02409/hybrid_auto/images/1706.02409_page0_fig9.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1706.02409_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Can the style-invariant latent representation used to generate all ten MNIST digits with consistent handwriting also preserve utility above 0.7 when enforcing disparate impact fairness constraints at DI=0.8?", "answer": "The MNIST style-invariant representation separates digit class from writing style by pushing non-class information into latent space, enabling generation of all digits with consistent handwriting. However, the fairness-utility tradeoff shown for Adult Income, German Credit, and Ricci datasets reveals that enforcing DI≥0.8 typically reduces utility from ~1.0 to 0.5-0.9 range, suggesting similar representation separation for fairness would likely incur comparable utility costs even with style-preserving generative models.", "query_type": "cross_synthesis", "turns": ["Can the style-invariant latent representation used to generate all ten MNIST digits with consistent handwriting also preserve utility above 0.7 when enforcing disparate impact fairness constraints at DI=0.8?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Scatter points with dashed trend lines showing utility declining from ~1.0 to 0.5-0.9 as disparate impact approaches the green vertical line at DI=1.0, with red vertical line marking DI=0.8 threshold", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases. Recall that only points with DI ≥ τ = 0.8 are legal."}, {"doc_id": "1805.09458", "anchor": "Top row showing real digit 9 on left generating stylistically consistent sequence 0123456789 on right, demonstrating style preservation across all digit classes", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}], "pair": {"doc_a": "1412.3756", "doc_b": "1805.09458"}, "shared_entities": ["accuracy", "logistic regression"], "pair_score": 13.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1805.09458_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "How does achieving full fairness (DI=1.0) through combinatorial repair on Adult Income data compare to FairGAN's ability to match conditional distributions P(x|s=1) and P(x|s=0) in terms of utility preservation?", "answer": "Combinatorial repair achieves DI=1.0 (full fairness) but suffers utility decay to approximately 0.7-0.9 on Adult Income data, demonstrating significant performance loss. FairGAN successfully matches conditional distributions P(x|s=1) and P(x|s=0) to closely align with the overall distribution P(x), as shown by the overlapping peaks near 0.05, suggesting fairness is achieved through generative modeling while the quality of synthetic data depends on how well these distributions align.", "query_type": "cross_comparison", "turns": ["How does achieving full fairness (DI=1.0) through combinatorial repair on Adult Income data compare to FairGAN's ability to match conditional distributions P(x|s=1) and P(x|s=0) in terms of utility preservation?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Scatter points at green vertical line (DI=1.0) in Adult Income panel showing utility values between 0.7-0.9", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases. DI=1.0 represents full fairness."}, {"doc_id": "1805.11202", "anchor": "Green and red dashed curves (conditional distributions) closely matching and peaking below 0.05 near x≈3.5", "text_evidence": "shows the distributions P_data(x) (black), P_data(x|s=1) (green) and P_data(x|s=0) (red) of real data"}], "pair": {"doc_a": "1412.3756", "doc_b": "1805.11202"}, "shared_entities": ["Fairness", "disparate impact"], "pair_score": 13.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1805.11202/1805.11202/hybrid_auto/images/1805.11202_page0_fig4.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1805.11202_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "How does the utility-fairness tradeoff for linear models on Adult Income compare between the combinatorial repair approach and the fair classification baseline with oracle=LR?", "answer": "The combinatorial repair approach shows utility declining from ~0.75 to ~0.70 as disparate impact increases from 0.7 to 1.0 on Adult Income. In contrast, fair classification with oracle=LR (solid black line) slightly outperforms alternative methods on the Adult dataset, maintaining better relative test loss at equivalent constraint violations, making it the exception where the baseline dominates.", "query_type": "cross_comparison", "turns": ["How does the utility-fairness tradeoff for linear models on Adult Income compare between the combinatorial repair approach and the fair classification baseline with oracle=LR?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "scatter points with dashed trend line in Adult Income panel showing utility decline from ~0.75 to ~0.70", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases."}, {"doc_id": "1905.12843", "anchor": "solid black line (fair class., oracle=LR, model=linear) in Adult Income bottom plot", "text_evidence": "Our method dominates or matches the baselines up to statistical uncertainty on all datasets except adult, where fair classification is slightly better."}], "pair": {"doc_a": "1412.3756", "doc_b": "1905.12843"}, "shared_entities": ["LR", "accuracy", "logistic regression"], "pair_score": 13.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1905.12843/1905.12843/hybrid_auto/images/1905.12843_page0_fig3.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1905.12843_fig_4", "qc_issues": [], "qc_pass": true}
{"query": "How does modeling nuisance variables S that directly affect observations X relate to the fairness-accuracy tradeoffs observed when LR and RF classifiers achieve disparate impact near 0.8?", "answer": "The unsupervised model shows nuisance variable S directly affecting observed data X, representing uninformative dimensions detrimental to tasks. Similarly, the fairness evaluation reveals that LR and RF classifiers with optimized pre-processing achieve disparate impact around 0.8 while maintaining balanced accuracy near 0.73-0.75, suggesting successful mitigation of nuisance bias factors that would otherwise degrade both fairness and performance.", "query_type": "cross_synthesis", "turns": ["How does modeling nuisance variables S that directly affect observations X relate to the fairness-accuracy tradeoffs observed when LR and RF classifiers achieve disparate impact near 0.8?"], "evidence_refs": [{"doc_id": "1511.00830", "anchor": "arrow from node S directly to node X in the graphical model", "text_evidence": "Uninformative dimensions are often called \"noise\" or \"nuisance variables\" while informative dimensions are usually called latent or hidden factors of variation."}, {"doc_id": "1810.01943", "anchor": "green and orange circles at disparate impact ~0.8 with balanced accuracy ~0.73-0.75 in top panel", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0. The circles indicate the mean value"}], "pair": {"doc_a": "1511.00830", "doc_b": "1810.01943"}, "shared_entities": ["LR", "RF", "accuracy"], "pair_score": 13.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1511.00830_fig_1", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Does the latent-space covariate approach that generates all ten MNIST digits from a single style achieve fairness-accuracy tradeoffs comparable to constrained logistic regression with SP oracle?", "answer": "The latent-space covariate method demonstrates style-invariant generation across all ten digit classes by separating stylistic information from digit labels in the latent space. However, the fairness-accuracy analysis shows that constrained logistic regression with statistical parity oracle (solid red line) achieves minimal constraint violation while maintaining competitive relative test loss, suggesting different optimization objectives: one prioritizes generative class coverage, the other explicit fairness-accuracy tradeoffs under constraints.", "query_type": "cross_comparison", "turns": ["Does the latent-space covariate approach that generates all ten MNIST digits from a single style achieve fairness-accuracy tradeoffs comparable to constrained logistic regression with SP oracle?"], "evidence_refs": [{"doc_id": "1805.09458", "anchor": "Top row showing real digit 9 generating sequence 0123456789 with consistent style", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}, {"doc_id": "1905.12843", "anchor": "Solid red line (fair reg. oracle=LS, model=linear) showing low constraint violation with competitive relative loss", "text_evidence": "Our method dominates or matches the baselines up to statistical uncertainty on all datasets except adult, where fair classification is slightly better."}], "pair": {"doc_a": "1805.09458", "doc_b": "1905.12843"}, "shared_entities": ["accuracy", "logistic regression"], "pair_score": 13.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_b_image_path": "data/mineru_output/1905.12843/1905.12843/hybrid_auto/images/1905.12843_page0_fig3.jpg", "doc_a_figure_id": "1805.09458_fig_5", "doc_b_figure_id": "1905.12843_fig_4", "qc_issues": [], "qc_pass": true}
{"query": "How does the fairness-utility tradeoff at DI=0.8 for Adult Income using combinatorial repair compare to false positive rate disparities for defendants with 0 priors in COMPAS?", "answer": "The combinatorial repair process on Adult Income maintains utility around 0.7-0.75 when reaching the legal DI threshold of 0.8, showing a moderate fairness-utility tradeoff. In contrast, COMPAS exhibits substantial false positive rate disparities at 0 priors (Black defendants ~0.22, White defendants ~0.08), revealing unfairness even at low risk levels where algorithmic intervention could more easily achieve parity without sacrificing predictive performance.", "query_type": "cross_comparison", "turns": ["How does the fairness-utility tradeoff at DI=0.8 for Adult Income using combinatorial repair compare to false positive rate disparities for defendants with 0 priors in COMPAS?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Scatter points near the red vertical line at DI=0.8 in the Adult Income/Combinatorial Repair panel showing utility values around 0.7-0.75", "text_evidence": "Recall that only points with $\\mathsf { D } \\mathsf { I } \\ge \\tau = 0 . 8$ are legal."}, {"doc_id": "1610.07524", "anchor": "Gray bar at ~0.22 and orange bar at ~0.08 in the leftmost category (0 priors) showing substantial separation between Black and White defendants", "text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2)."}], "pair": {"doc_a": "1412.3756", "doc_b": "1610.07524"}, "shared_entities": ["disparate impact", "logistic regression"], "pair_score": 13.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1610.07524_fig_2", "qc_issues": [], "qc_pass": true}
{"query": "How does the fairness-utility tradeoff structure differ between the combinatorial repair approach showing discrete scatter points and the Pareto frontier approach displaying continuous curves across multiple gamma values?", "answer": "The combinatorial and geometric repair processes produce discrete tradeoff points along dashed trend lines for each dataset-classifier combination, with utility declining from ~1.0 to ~0.5-0.9 as disparate impact approaches 1.0. In contrast, the Pareto-optimal approach generates continuous curves color-coded by gamma parameter, forming a dense aggregate frontier that smoothly maps error-unfairness tradeoffs across the entire parameter space rather than discrete repair steps.", "query_type": "cross_comparison", "turns": ["How does the fairness-utility tradeoff structure differ between the combinatorial repair approach showing discrete scatter points and the Pareto frontier approach displaying continuous curves across multiple gamma values?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Discrete scatter points connected by dashed trend lines showing declining utility from left to right across DI values", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases."}, {"doc_id": "1711.05144", "anchor": "Multiple distinct colored curves (blue, red, green, purple, orange) forming continuous trajectories and aggregate smooth frontier", "text_evidence": "Pareto-optimal error-unfairness values, color coded by varying values of the input parameter γ. Here the γ values cover the same range but are sampled more densely to get a smoother frontier."}], "pair": {"doc_a": "1412.3756", "doc_b": "1711.05144"}, "shared_entities": ["accuracy", "disparate impact"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1711.05144/1711.05144/hybrid_auto/images/1711.05144_page0_fig2.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1711.05144_fig_3", "qc_issues": [], "qc_pass": true}
{"query": "How does fairness regularization's Price of Fairness tradeoff at alpha=0.01 compare to the covariate-based style-class separation approach for maintaining performance while enforcing constraints?", "answer": "Fairness regularization at alpha=0.01 shows Price of Fairness reaching 1.5-1.6 (hybrid bars), indicating 50-60% performance loss for strict fairness constraints. In contrast, covariate-based separation using digit labels as class c removes class information from latent space z while preserving stylistic variation, enabling constraint satisfaction without explicit accuracy penalties through architectural design rather than regularization strength.", "query_type": "cross_comparison", "turns": ["How does fairness regularization's Price of Fairness tradeoff at alpha=0.01 compare to the covariate-based style-class separation approach for maintaining performance while enforcing constraints?"], "evidence_refs": [{"doc_id": "1706.02409", "anchor": "magenta and yellow hybrid bars at alpha=0.01 reaching heights of 1.5-1.6", "text_evidence": "The 'Price of Fairness' across data sets, for each type of fairness regularizer, in both the single and separate model case."}, {"doc_id": "1805.09458", "anchor": "real digit 9 generating all ten digits 0-9 with preserved style in top row", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}], "pair": {"doc_a": "1706.02409", "doc_b": "1805.09458"}, "shared_entities": ["accuracy", "logistic regression"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1706.02409/1706.02409/hybrid_auto/images/1706.02409_page0_fig9.jpg", "doc_b_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_a_figure_id": "1706.02409_fig_10", "doc_b_figure_id": "1805.09458_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "How does the fairness-accuracy tradeoff for logistic regression compare between the hybrid regularizer at alpha=0.01 and the optimized pre-processing method at disparate impact 0.8?", "answer": "The hybrid regularizer at alpha=0.01 shows Price of Fairness reaching approximately 1.6 for the separate model case, indicating substantial accuracy loss for fairness. In contrast, logistic regression with optimized pre-processing achieves disparate impact near 0.75 while maintaining balanced accuracy around 0.73-0.74, demonstrating a more favorable fairness-accuracy balance than the heavily regularized hybrid approach.", "query_type": "cross_comparison", "turns": ["How does the fairness-accuracy tradeoff for logistic regression compare between the hybrid regularizer at alpha=0.01 and the optimized pre-processing method at disparate impact 0.8?"], "evidence_refs": [{"doc_id": "1706.02409", "anchor": "magenta and yellow bars at alpha=0.01 reaching height ~1.6", "text_evidence": "As alpha decreases (stronger regularization), the hybrid fairness regularizers show increasing Price of Fairness, indicating that stricter hybrid fairness constraints progressively sacrifice more model performance"}, {"doc_id": "1810.01943", "anchor": "orange circles (LR,Optimized pre-processing) at disparate impact ~0.75 and balanced accuracy ~0.73-0.74", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0. The circles indicate the mean value"}], "pair": {"doc_a": "1706.02409", "doc_b": "1810.01943"}, "shared_entities": ["Fairness", "accuracy", "logistic regression"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1706.02409/1706.02409/hybrid_auto/images/1706.02409_page0_fig9.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1706.02409_fig_10", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Can the latent-space style extraction that preserves handwriting style across MNIST digit classes achieve fairness-accuracy tradeoffs comparable to optimized pre-processing methods at disparate impact 0.8?", "answer": "The MNIST style-preserving generative model removes class information from latent space z to enable digit-invariant style transfer, focusing on representation learning rather than fairness metrics. In contrast, optimized pre-processing achieves disparate impact near 0.8 with balanced accuracy around 0.73-0.75 for both logistic regression and random forest classifiers, explicitly targeting fairness-utility tradeoffs through bias mitigation rather than style preservation.", "query_type": "cross_comparison", "turns": ["Can the latent-space style extraction that preserves handwriting style across MNIST digit classes achieve fairness-accuracy tradeoffs comparable to optimized pre-processing methods at disparate impact 0.8?"], "evidence_refs": [{"doc_id": "1805.09458", "anchor": "Left column real digit 9 mapped to latent z generating all digits 0-9 rightward", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}, {"doc_id": "1810.01943", "anchor": "Green and orange circles at disparate impact 0.8 in top panel showing balanced accuracy 0.73-0.75", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0. In most cases two classifiers (Logistic regression - LR or Random forest classifier - RF) were used."}], "pair": {"doc_a": "1805.09458", "doc_b": "1810.01943"}, "shared_entities": ["accuracy", "logistic regression"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1805.09458_fig_5", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Does achieving a disparate impact of 1 in the bias mitigation algorithms guarantee that the conditional distributions P(x|s=1) and P(x|s=0) become identical?", "answer": "No. Achieving disparate impact of 1 (shown by green circles at ~0.8 in the top panel with RF optimized pre-processing) indicates equal selection rates between groups, but does not guarantee identical conditional distributions. The toy dataset demonstrates that P(x|s=1) (green dashed) and P(x|s=0) (red dashed) can remain distinct with different peak heights and positions even when fairness metrics are optimized, as disparate impact measures outcome parity rather than distributional equivalence.", "query_type": "cross_synthesis", "turns": ["Does achieving a disparate impact of 1 in the bias mitigation algorithms guarantee that the conditional distributions P(x|s=1) and P(x|s=0) become identical?"], "evidence_refs": [{"doc_id": "1805.11202", "anchor": "Green dashed curve P(x|s=1) and red dashed curve P(x|s=0) showing distinct peak heights and positions", "text_evidence": "shows the distributions P_data(x) (black), P_data(x|s=1) (green) and P_data(x|s=0) (red) of real data"}, {"doc_id": "1810.01943", "anchor": "Green circles at disparate impact ~0.8 in top panel representing RF,Optimized pre-processing", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0"}], "pair": {"doc_a": "1805.11202", "doc_b": "1810.01943"}, "shared_entities": ["Fairness", "disparate impact"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1805.11202/1805.11202/hybrid_auto/images/1805.11202_page0_fig4.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1805.11202_fig_5", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Does the latent space learned by digit-conditioned generation on MNIST produce clustered embeddings by digit class, or would a t-SNE visualization resemble the lighting-condition separation seen in Extended Yale-B?", "answer": "The digit-conditioned generation explicitly removes digit identity from the latent space z by using digit label as covariate c, pushing only stylistic information into z. Therefore, a t-SNE visualization of z would not cluster by digit class like the lighting-condition separation in Extended Yale-B embeddings e₁, which explicitly disentangle and preserve lighting as a distinct factor.", "query_type": "cross_synthesis", "turns": ["Does the latent space learned by digit-conditioned generation on MNIST produce clustered embeddings by digit class, or would a t-SNE visualization resemble the lighting-condition separation seen in Extended Yale-B?"], "evidence_refs": [{"doc_id": "1805.09458", "anchor": "Left column real digits mapping to z, generating all ten digits 0-9 rightward", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}, {"doc_id": "1809.10083", "anchor": "Spatial separation between orange lower-right and cyan upper-right markers in e₁ t-SNE plot", "text_evidence": "Figure 2 shows t-SNE [15] visualization of raw data and embeddings $e _ { 1 }$ and $e _ { 2 }$ for our model."}], "pair": {"doc_a": "1805.09458", "doc_b": "1809.10083"}, "shared_entities": ["MNIST", "SNE", "t-SNE"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_b_image_path": "data/mineru_output/1809.10083/1809.10083/hybrid_auto/images/1809.10083_page0_fig4.jpg", "doc_a_figure_id": "1805.09458_fig_5", "doc_b_figure_id": "1809.10083_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "How does the clustering of red violations at lower training ratios in RBA results relate to the exclusion of low-degree nodes shown in the gray sector?", "answer": "Red dots at lower training ratios indicate models violating the 0.05 bias margin before RBA correction, representing systematic bias amplification. Similarly, the gray sector's mixed community illustrates how biased detection methods exclude low-degree nodes or assign them to trivially small communities, both demonstrating how initial bias in training or connectivity leads to systematic exclusion of underrepresented groups.", "query_type": "cross_synthesis", "turns": ["How does the clustering of red violations at lower training ratios in RBA results relate to the exclusion of low-degree nodes shown in the gray sector?"], "evidence_refs": [{"doc_id": "1707.09457", "anchor": "red dots clustered at lower x-axis values (training gender ratio 0.35-0.6)", "text_evidence": "points violating the margin shown in red while points meeting the margin are shown in green. Across both settings adding RBA significantly re"}, {"doc_id": "1903.08136", "anchor": "gray quarter-circle sector containing mixed blue triangles and red circles with various textures", "text_evidence": "many community detection approaches either fail to assign low degree (or lowly-connected) users to communities, or assign them to trivially small communities that prevent them from being included in analysis"}], "pair": {"doc_a": "1707.09457", "doc_b": "1903.08136"}, "shared_entities": ["In Figure"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1707.09457/1707.09457/hybrid_auto/images/1707.09457_page0_fig6.jpg", "doc_b_image_path": "data/mineru_output/1903.08136/1903.08136/hybrid_auto/images/1903.08136_page0_fig0.jpg", "doc_a_figure_id": "1707.09457_fig_7", "doc_b_figure_id": "1903.08136_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Do the overlapping risk-score distributions in the simulated beta data satisfy the equity principle requiring compensatory resource allocation for historically disadvantaged groups?", "answer": "No. The simulated distributions achieve equal means but violate statistical parity by differing in shape (blue peaks before 25%, red after), which indicates unequal detention rates across groups. Equity demands compensatory allocation—like the taller box under the yellow figure—to overcome obstacles and equalize access, not merely equal means that preserve disparate outcomes.", "query_type": "cross_synthesis", "turns": ["Do the overlapping risk-score distributions in the simulated beta data satisfy the equity principle requiring compensatory resource allocation for historically disadvantaged groups?"], "evidence_refs": [{"doc_id": "1701.08230", "anchor": "Blue and red curves with vertical dashed line at 25% in simulated panel showing different peak locations despite equal means", "text_evidence": "simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains 30% of defendants in Broward County violates statistical parity (as measured by detention rate)"}, {"doc_id": "2005.07293", "anchor": "Right panel 'Equity' showing yellow figure on tallest brown box to reach apples", "text_evidence": "Equity is the distribution of resources among groups to overcome obstacles and to raise their opportunities for access. Thus, historically disadvantaged groups are compensated, and others get their fair share to reach their goals."}], "pair": {"doc_a": "1701.08230", "doc_b": "2005.07293"}, "shared_entities": ["COMPAS", "parity"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig0.jpg", "doc_a_figure_id": "1701.08230_fig_2", "doc_b_figure_id": "2005.07293_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Can the rising false positive rates for Black defendants with more priors in COMPAS be reconciled with an equity framework that allocates compensatory resources to historically disadvantaged groups?", "answer": "COMPAS exhibits increasing false positive rates for Black defendants as prior record count grows (from ~0.22 at zero priors to ~0.92 at >10 priors), contradicting equity principles. Equity requires distributing resources to overcome obstacles for historically disadvantaged groups, yet COMPAS systematically assigns higher risk scores—and thus harsher treatment—to Black defendants with more priors, denying rather than compensating for structural disadvantage.", "query_type": "cross_contradiction", "turns": ["Can the rising false positive rates for Black defendants with more priors in COMPAS be reconciled with an equity framework that allocates compensatory resources to historically disadvantaged groups?"], "evidence_refs": [{"doc_id": "1610.07524", "anchor": "Gray bars increasing from ~0.22 at 0 priors to ~0.92 at >10 priors for Black defendants", "text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2)."}, {"doc_id": "2005.07293", "anchor": "Right panel 'Equity' showing yellow figure on tallest brown box representing compensatory resource distribution", "text_evidence": "Equity is the distribution of resources among groups to overcome obstacles and to raise their opportunities for access [Schement, 2001]. Thus, historically disadvantaged groups are compensated, and others get their fair share to reach their goals."}], "pair": {"doc_a": "1610.07524", "doc_b": "2005.07293"}, "shared_entities": ["COM", "COMPAS", "PAS"], "pair_score": 12.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig0.jpg", "doc_a_figure_id": "1610.07524_fig_2", "doc_b_figure_id": "2005.07293_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does the presence of nuisance variable S affecting observed data X relate to the utility degradation seen when enforcing disparate impact constraints above DI=0.8?", "answer": "The nuisance variable S directly affecting X in unsupervised learning represents uninformative dimensions that degrade model performance, similar to how enforcing fairness constraints (DI≥0.8) causes utility to decay from ~1.0 to 0.5-0.9 across all datasets. Both scenarios demonstrate that introducing constraints or noise—whether from nuisance variables or fairness requirements—reduces predictive accuracy, though fairness repair explicitly trades utility for legal compliance while nuisance variables provide no compensating benefit.", "query_type": "cross_synthesis", "turns": ["How does the presence of nuisance variable S affecting observed data X relate to the utility degradation seen when enforcing disparate impact constraints above DI=0.8?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "Dashed trend lines showing utility declining from ~1.0 to ~0.5-0.9 as disparate impact approaches the green vertical line at DI=1.0", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases."}, {"doc_id": "1511.00830", "anchor": "Arrow from node S directly to node X bypassing Z", "text_evidence": "Uninformative dimensions are often called 'noise' or 'nuisance variables' while informative dimensions are usually called latent or hidden factors of variation."}], "pair": {"doc_a": "1412.3756", "doc_b": "1511.00830"}, "shared_entities": ["LR", "accuracy"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig0.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1511.00830_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does logistic regression perform in fairness-accuracy tradeoffs: does optimized pre-processing achieve disparate impact near 1 with similar accuracy loss to fair classification methods under SP constraints?", "answer": "Optimized pre-processing with LR achieves disparate impact around 0.8 (close to ideal value 1) in the top panel, demonstrating strong fairness before mitigation. Fair classification with LR (solid black line in bottom plots) shows competitive performance with minimal constraint violation under SP, though it is slightly outperformed on most datasets except adult. Both methods using logistic regression demonstrate effective fairness-accuracy tradeoffs, with optimized pre-processing excelling at disparate impact metrics while fair classification minimizes SP constraint violations.", "query_type": "cross_synthesis", "turns": ["How does logistic regression perform in fairness-accuracy tradeoffs: does optimized pre-processing achieve disparate impact near 1 with similar accuracy loss to fair classification methods under SP constraints?"], "evidence_refs": [{"doc_id": "1810.01943", "anchor": "green circles (LR,Optimized pre-processing) at disparate impact ~0.8 in top panel", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0."}, {"doc_id": "1905.12843", "anchor": "solid black line (fair class., oracle=LR, model=linear) in bottom plots", "text_evidence": "Our method dominates or matches the baselines up to statistical uncertainty on all datasets except adult, where fair classification is slightly better."}], "pair": {"doc_a": "1810.01943", "doc_b": "1905.12843"}, "shared_entities": ["LR", "accuracy", "logistic regression"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_b_image_path": "data/mineru_output/1905.12843/1905.12843/hybrid_auto/images/1905.12843_page0_fig3.jpg", "doc_a_figure_id": "1810.01943_fig_10", "doc_b_figure_id": "1905.12843_fig_4", "qc_issues": [], "qc_pass": true}
{"query": "Can logistic regression achieve equal false positive rates across racial groups while maintaining disparate impact above 0.8 in both COMPAS misdemeanor and optimized pre-processing scenarios?", "answer": "COMPAS misdemeanor data shows persistent false positive rate differences between Black and White defendants across all prior categories even when overall FPR equality holds, indicating within-category disparities. Optimized pre-processing with logistic regression achieves disparate impact around 0.75 (ideal is 1.0), suggesting that equal overall FPR does not guarantee disparate impact fairness, as category-level differences can still produce aggregate bias metrics below 0.8.", "query_type": "cross_synthesis", "turns": ["Can logistic regression achieve equal false positive rates across racial groups while maintaining disparate impact above 0.8 in both COMPAS misdemeanor and optimized pre-processing scenarios?"], "evidence_refs": [{"doc_id": "1610.07524", "anchor": "Consistent separation between gray (Black) and orange (White) bars across all five x-axis categories showing different false positive rates", "text_evidence": "That is, even if $\\mathrm { F P R } _ { b } = \\mathrm { F P R } _ { w }$ , we may still see differences in error rates within prior record score categories (see e.g., Figure 2)."}, {"doc_id": "1810.01943", "anchor": "Orange circles (LR,Optimized pre-processing) at disparate impact approximately 0.75 in top panel", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0."}], "pair": {"doc_a": "1610.07524", "doc_b": "1810.01943"}, "shared_entities": ["disparate impact", "logistic regression"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1610.07524/1610.07524/hybrid_auto/images/1610.07524_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1610.07524_fig_2", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "Could unobserved confounders like those represented by the gray node C explain the utility decay observed in the German Credit scatter points as disparate impact increases?", "answer": "Yes, unobserved confounders could partially explain the utility decay pattern. The German Credit scatter points show utility declining from ~0.7 to ~0.6 as disparate impact moves toward 1.0, which could reflect unmeasured common causes affecting both protected attributes and outcomes. Such confounders, represented by bidirected links in ADMG notation, would make the causal effect along fairness interventions unidentifiable using only observed variables, potentially contributing to the observed utility-fairness tradeoff.", "query_type": "cross_synthesis", "turns": ["Could unobserved confounders like those represented by the gray node C explain the utility decay observed in the German Credit scatter points as disparate impact increases?"], "evidence_refs": [{"doc_id": "1412.3756", "anchor": "German Credit scatter points with dashed trend line showing utility declining from ~0.7 to ~0.6 as disparate impact increases", "text_evidence": "The results, shown in Figure 3, demonstrate the expected decay over utility as fairness increases."}, {"doc_id": "1802.08139", "anchor": "Gray node C in subfigure (a) and red bidirected edge in subfigure (b) representing unobserved confounder", "text_evidence": "An ADMG is a causal graph containing two kinds of links, directed links (either green or black depending on whether we are interested in the corresponding causal path), and red bidirected links, indicating the presence of an unobserved common cause. The causal effect along the green path A → Y cannot be identified by only using observed variables."}], "pair": {"doc_a": "1412.3756", "doc_b": "1802.08139"}, "shared_entities": ["German Credit"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1412.3756/1412.3756/hybrid_auto/images/1412.3756_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1802.08139/1802.08139/hybrid_auto/images/1802.08139_page0_fig16.jpg", "doc_a_figure_id": "1412.3756_fig_3", "doc_b_figure_id": "1802.08139_fig_17", "qc_issues": [], "qc_pass": true}
{"query": "Does the diagonal blue-to-red gradient in reputation-answer acceptance probability reflect the same style-invariant separation mechanism that allows a single MNIST digit to generate all ten classes?", "answer": "No. The diagonal gradient reflects probability mass shifting with two continuous covariates (reputation and answer count) in a Simpson's paradox analysis, not a style-content separation. In contrast, the MNIST generation uses digit label as a discrete covariate to push all non-class stylistic information into latent space, enabling recombination of extracted style with any specified digit label to produce all ten digits.", "query_type": "cross_contradiction", "turns": ["Does the diagonal blue-to-red gradient in reputation-answer acceptance probability reflect the same style-invariant separation mechanism that allows a single MNIST digit to generate all ten classes?"], "evidence_refs": [{"doc_id": "1801.04385", "anchor": "Diagonal gradient transitioning from blue (lower-left, acceptance ~0.0) to red (upper-right, acceptance ~0.7) across reputation 10^2-10^6 and answer count 10^1-10^4", "text_evidence": "Average acceptance probability as a function of two variables. The rate of change of these probability masses with respect to Xp"}, {"doc_id": "1805.09458", "anchor": "Top row showing real digit 9 on left generating sequence 0123456789 on right using covariate-based style extraction", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written. We then can generate an image using z and any other specified digit, c′"}], "pair": {"doc_a": "1801.04385", "doc_b": "1805.09458"}, "shared_entities": ["logistic regression"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1801.04385/1801.04385/hybrid_auto/images/1801.04385_page0_fig4.jpg", "doc_b_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_a_figure_id": "1801.04385_fig_5", "doc_b_figure_id": "1805.09458_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "How does the proportional-share principle illustrated by two red centers differ from the bias-reduction goal shown by green dots meeting the margin constraint?", "answer": "The two red centers demonstrate proportional fairness by allocating k=2 centers equally to groups N and M of equal size, ensuring each group receives its entitled share. In contrast, green dots represent successful bias amplification reduction where predicted gender ratios stay within 0.05 margin of training ratios, constraining rather than allocating resources proportionally.", "query_type": "cross_comparison", "turns": ["How does the proportional-share principle illustrated by two red centers differ from the bias-reduction goal shown by green dots meeting the margin constraint?"], "evidence_refs": [{"doc_id": "1905.03674", "anchor": "two red dots positioned symmetrically on left and right sides", "text_evidence": "Proportionality has many advantages as a notion of fairness in clustering, beyond the intuitive appeal of groups being entitled to a proportional share of centers."}, {"doc_id": "1707.09457", "anchor": "green dots in upper-right region meeting the margin constraint", "text_evidence": "Dotted blue lines indicate the 0.05 margin used in RBA, with points violating the margin shown in red while points meeting the margin are shown in green."}], "pair": {"doc_a": "1707.09457", "doc_b": "1905.03674"}, "shared_entities": ["In Figure"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1707.09457/1707.09457/hybrid_auto/images/1707.09457_page0_fig6.jpg", "doc_b_image_path": "data/mineru_output/1905.03674/1905.03674/hybrid_auto/images/1905.03674_page0_fig0.jpg", "doc_a_figure_id": "1707.09457_fig_7", "doc_b_figure_id": "1905.03674_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does the calibrated classifier frontier in the FN-FP plane relate to the resource-allocation mechanism illustrated by the different-height boxes in the equity framework?", "answer": "The calibrated classifier sets H₁* and H₂* on the black diagonal boundary represent group-specific Pareto-optimal trade-offs between false positives and false negatives, achieving parity in predictive performance metrics. The different-height boxes under each figure in the equity panel operationalize compensatory resource distribution to overcome obstacles, providing historically disadvantaged groups with additional support to reach equal outcomes—a form of outcome parity that differs from the predictive parity enforced by calibration constraints.", "query_type": "cross_synthesis", "turns": ["How does the calibrated classifier frontier in the FN-FP plane relate to the resource-allocation mechanism illustrated by the different-height boxes in the equity framework?"], "evidence_refs": [{"doc_id": "1709.02012", "anchor": "Black diagonal line with H₁* and H₂* calibrated classifier sets in FN-FP plane", "text_evidence": "H₁*, H₂* are the set of cal. classifiers for the two groups"}, {"doc_id": "2005.07293", "anchor": "Right panel 'Equity' showing different-height brown boxes under each figure, with yellow figure on tallest box", "text_evidence": "Equity is the distribution of resources among groups to overcome obstacles and to raise their opportunities for access. Thus, historically disadvantaged groups are compensated, and others get their fair share to reach their goals."}], "pair": {"doc_a": "1709.02012", "doc_b": "2005.07293"}, "shared_entities": ["Parity", "parity"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1709.02012/1709.02012/hybrid_auto/images/1709.02012_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig0.jpg", "doc_a_figure_id": "1709.02012_fig_3", "doc_b_figure_id": "2005.07293_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Does the fairness-accuracy tradeoff observed when varying λ in MTL align with the indirect causal paths through marital_status identified in the Adult causal network?", "answer": "Yes, the tradeoff aligns with the causal structure. The blue indirect paths through marital_status in the causal network reveal how sex influences income through this mediator, creating potential unfairness. When λ increases from 2e-10 to 1 in MTL, ACC drops from ~91% to ~67% while EOd rises from ~0.05 to ~0.13, showing that mitigating bias along these indirect causal pathways requires sacrificing accuracy.", "query_type": "cross_synthesis", "turns": ["Does the fairness-accuracy tradeoff observed when varying λ in MTL align with the indirect causal paths through marital_status identified in the Adult causal network?"], "evidence_refs": [{"doc_id": "1611.07509", "anchor": "blue paths from sex through marital_status node to income versus green direct path", "text_evidence": "the blue paths represent the indirect paths passing through marital status"}, {"doc_id": "1810.08683", "anchor": "opposing trends of blue ACC declining from ~91 to ~67 and orange EOd rising from ~0.05 to ~0.13 in bottom panel", "text_evidence": "we check how the accuracy and fairness, as measured with the EOd, varies by varying λ"}], "pair": {"doc_a": "1611.07509", "doc_b": "1810.08683"}, "shared_entities": ["The Adult"], "pair_score": 12.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1611.07509/1611.07509/hybrid_auto/images/1611.07509_page0_fig3.jpg", "doc_b_image_path": "data/mineru_output/1810.08683/1810.08683/hybrid_auto/images/1810.08683_page0_fig3.jpg", "doc_a_figure_id": "1611.07509_fig_4", "doc_b_figure_id": "1810.08683_fig_4", "qc_issues": [], "qc_pass": true}
{"query": "How does the direct influence of noise variable S on observed data X in unsupervised models relate to constraint violations observed with logistic regression oracles in fairness-constrained learning?", "answer": "The direct S→X edge models how noise variables directly affect observed data independent of informative latent factors Z in unsupervised representation learning. In fairness-constrained settings, logistic regression oracles (LR) with linear models show minimal constraint violations while maintaining competitive test loss, suggesting that properly modeling nuisance variables during training can reduce fairness-accuracy tradeoffs.", "query_type": "cross_synthesis", "turns": ["How does the direct influence of noise variable S on observed data X in unsupervised models relate to constraint violations observed with logistic regression oracles in fairness-constrained learning?"], "evidence_refs": [{"doc_id": "1511.00830", "anchor": "arrow from node S (top-left) directly to node X (bottom-center)", "text_evidence": "Uninformative dimensions are often called 'noise' or 'nuisance variables' while informative dimensions are usually called latent or hidden factors of variation."}, {"doc_id": "1905.12843", "anchor": "solid blue line (fair reg., oracle=LR, model=linear) in bottom plots showing low constraint violation", "text_evidence": "Our method dominates or matches the baselines up to statistical uncertainty on all datasets except adult, where fair classification is slightly better."}], "pair": {"doc_a": "1511.00830", "doc_b": "1905.12843"}, "shared_entities": ["LR", "accuracy"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1905.12843/1905.12843/hybrid_auto/images/1905.12843_page0_fig3.jpg", "doc_a_figure_id": "1511.00830_fig_1", "doc_b_figure_id": "1905.12843_fig_4", "qc_issues": [], "qc_pass": true}
{"query": "Does the Pareto frontier gamma-based approach achieve disparate impact values closer to 1.0 compared to the optimized pre-processing method with logistic regression and random forest classifiers?", "answer": "The gamma-based Pareto frontier approach shows error values ranging from approximately 0.1 to 0.3 across varying gamma parameters, but does not directly display disparate impact metrics. In contrast, optimized pre-processing with LR and RF achieves disparate impact values around 0.75-0.8 (top panel), which are farther from the ideal value of 1.0, suggesting different fairness metric optimization strategies between the two approaches.", "query_type": "cross_comparison", "turns": ["Does the Pareto frontier gamma-based approach achieve disparate impact values closer to 1.0 compared to the optimized pre-processing method with logistic regression and random forest classifiers?"], "evidence_refs": [{"doc_id": "1711.05144", "anchor": "Multiple distinct colored curves showing error vs gamma values ranging from 0.1 to 0.3", "text_evidence": "Pareto-optimal error-unfairness values, color coded by varying values of the input parameter γ"}, {"doc_id": "1810.01943", "anchor": "Orange and green circles at disparate impact 0.75-0.8 in top panel", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0"}], "pair": {"doc_a": "1711.05144", "doc_b": "1810.01943"}, "shared_entities": ["accuracy", "disparate impact"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1711.05144/1711.05144/hybrid_auto/images/1711.05144_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1711.05144_fig_3", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "How does the discriminator-based filtering architecture for multiple sensitive attributes compare to the structured latent code approach in maintaining accuracy while achieving fairness across age, gender, and occupation?", "answer": "The discriminator-based filtering uses adversarial discriminators (D_Gender, D_Occupation, D_Age) to prevent classification of sensitive information from filtered embeddings, composing filters flexibly for graph data. The structured latent code approach (FFVAE) maintains higher accuracy (above 0.75) across fairness levels by disentangling multiple sensitive attributes (Chubby, Eyeglasses, Male) in image data, demonstrating superior fairness-accuracy tradeoff compared to baseline methods.", "query_type": "cross_comparison", "turns": ["How does the discriminator-based filtering architecture for multiple sensitive attributes compare to the structured latent code approach in maintaining accuracy while achieving fairness across age, gender, and occupation?"], "evidence_refs": [{"doc_id": "1905.10674", "anchor": "Three discriminators (D_Gender, D_Occupation, D_Age) shown in pink boxes on the right side of the pipeline", "text_evidence": "We train a set of 'filters' to prevent adversarial discriminators from classifying the sensitive information from the filtered embeddings. After training, these filters can be composed together in different combinations"}, {"doc_id": "1906.02589", "anchor": "Solid blue FFVAE line maintaining accuracy above 0.75 across all Δ_CP values from 0.00 to 0.40", "text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes"}], "pair": {"doc_a": "1905.10674", "doc_b": "1906.02589"}, "shared_entities": ["MLP", "accuracy"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1905.10674/1905.10674/hybrid_auto/images/1905.10674_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg", "doc_a_figure_id": "1905.10674_fig_1", "doc_b_figure_id": "1906.02589_fig_29", "qc_issues": [], "qc_pass": true}
{"query": "Does achieving higher accuracy at Δ_CP=0.40 with FFVAE's structured latent code align with equality or equity fairness, given the different resource distributions needed for disadvantaged groups?", "answer": "FFVAE's high accuracy (≈0.80) at Δ_CP=0.40 using multiple sensitive attributes for disentanglement aligns with equality, ensuring equal prediction quality across subgroups. However, equity requires differential resource allocation—like taller boxes for the yellow figure—to compensate historically disadvantaged groups, which equal accuracy metrics alone cannot capture without considering group-specific obstacles.", "query_type": "cross_synthesis", "turns": ["Does achieving higher accuracy at Δ_CP=0.40 with FFVAE's structured latent code align with equality or equity fairness, given the different resource distributions needed for disadvantaged groups?"], "evidence_refs": [{"doc_id": "1906.02589", "anchor": "solid blue TEXAS line reaching ≈0.80 accuracy at Δ_CP=0.40", "text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes"}, {"doc_id": "2005.07293", "anchor": "Right panel 'Equity' showing yellow figure on tallest box versus equal-height boxes in 'Equality' left panel", "text_evidence": "Equity is the distribution of resources among groups to overcome obstacles and to raise their opportunities for access. Thus, historically disadvantaged groups are compensated, and others get their fair share to reach their goals."}], "pair": {"doc_a": "1906.02589", "doc_b": "2005.07293"}, "shared_entities": ["accuracy", "parity"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg", "doc_b_image_path": "data/mineru_output/2005.07293/2005.07293/hybrid_auto/images/2005.07293_page0_fig0.jpg", "doc_a_figure_id": "1906.02589_fig_29", "doc_b_figure_id": "2005.07293_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Can attention-weighted embeddings from the general classification model achieve the same accuracy-parity tradeoff as FFVAE's structured latent code on Celeb-A Heavy-Makeup prediction?", "answer": "FFVAE's structured latent code using multiple sensitive attributes (Chubby, Eyeglasses, Male) maintains accuracy above 0.80 across all Δ_CP values up to 0.40, demonstrating effective disentanglement for fairness. The attention layer computes weighted combinations of feature embeddings to produce sample representations, but this architecture lacks explicit sensitive attribute structuring needed to jointly optimize accuracy and demographic parity constraints as shown by FFVAE's superior performance.", "query_type": "cross_comparison", "turns": ["Can attention-weighted embeddings from the general classification model achieve the same accuracy-parity tradeoff as FFVAE's structured latent code on Celeb-A Heavy-Makeup prediction?"], "evidence_refs": [{"doc_id": "1906.02589", "anchor": "solid blue TEXAS line maintaining accuracy above 0.80 from Δ_CP 0.00 to 0.40", "text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes"}, {"doc_id": "2109.03952", "anchor": "orange Attention layer receiving embeddings from blue f_k circles and red e_k boxes", "text_evidence": "The Computation of attention weights and the final representation for a sample"}], "pair": {"doc_a": "1906.02589", "doc_b": "2109.03952"}, "shared_entities": ["accuracy", "parity"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg", "doc_b_image_path": "data/mineru_output/2109.03952/2109.03952/hybrid_auto/images/2109.03952_page0_fig0.jpg", "doc_a_figure_id": "1906.02589_fig_29", "doc_b_figure_id": "2109.03952_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Do the Pareto-optimal error-unfairness trajectories demonstrate the same multi-modal structure observed in the conditional distributions P(x|s=1) and P(x|s=0)?", "answer": "No, the Pareto frontiers show smooth monotonic trade-off curves between error and unfairness as gamma varies, with distinct colored trajectories converging toward lower error and unfairness. In contrast, the conditional distributions P(x|s=1) and P(x|s=0) exhibit multi-modal structures with multiple distinct peaks across the x-axis, representing fundamentally different data characteristics rather than optimization trade-offs.", "query_type": "cross_contradiction", "turns": ["Do the Pareto-optimal error-unfairness trajectories demonstrate the same multi-modal structure observed in the conditional distributions P(x|s=1) and P(x|s=0)?"], "evidence_refs": [{"doc_id": "1711.05144", "anchor": "Multiple distinct colored curves (blue, red, green, purple, orange) forming smooth descending trajectories from upper-left to lower-right", "text_evidence": "Pareto-optimal error-unfairness values, color coded by varying values of the input parameter γ"}, {"doc_id": "1805.11202", "anchor": "Green and red dashed curves showing multiple peaks at different x positions (around x=0, x=2, and x=3.5)", "text_evidence": "shows the distributions P_data(x) (black), P_data(x|s=1) (green) and P_data(x|s=0) (red) of real data"}], "pair": {"doc_a": "1711.05144", "doc_b": "1805.11202"}, "shared_entities": ["disparate impact"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1711.05144/1711.05144/hybrid_auto/images/1711.05144_page0_fig2.jpg", "doc_b_image_path": "data/mineru_output/1805.11202/1805.11202/hybrid_auto/images/1805.11202_page0_fig4.jpg", "doc_a_figure_id": "1711.05144_fig_3", "doc_b_figure_id": "1805.11202_fig_5", "qc_issues": [], "qc_pass": true}
{"query": "How does the two-orders-of-magnitude gap between cumulative subreddits and users in Reddit's growth relate to the exclusion of low-degree users by community detection methods?", "answer": "Reddit's structure shows many users distributed across relatively fewer subreddit communities (dashed teal line at ~10^5 subreddits versus purple line at ~10^7 users by 2014). This concentration means many users have low connectivity within individual communities, making them vulnerable to exclusion by methods like CESNA and Louvain that fail to assign low-degree nodes or place them in trivially small communities that prevent analysis inclusion.", "query_type": "cross_synthesis", "turns": ["How does the two-orders-of-magnitude gap between cumulative subreddits and users in Reddit's growth relate to the exclusion of low-degree users by community detection methods?"], "evidence_refs": [{"doc_id": "1603.07025", "anchor": "dashed teal line staying around 10^5 while solid purple line reaches 10^7 by 2014", "text_evidence": "The dashed teal line represents cumulative subreddits while the purple line shows cumulative users. Reddit's structure allows many users to participate across relatively fewer subreddit communities."}, {"doc_id": "1903.08136", "anchor": "gray quarter-circle sector with mixed blue triangles and red circles showing diverse low-degree participation", "text_evidence": "many community detection approaches either fail to assign low degree (or lowly-connected) users to communities, or assign them to trivially small communities that prevent them from being included in analysis"}], "pair": {"doc_a": "1603.07025", "doc_b": "1903.08136"}, "shared_entities": ["In Figure"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1603.07025/1603.07025/hybrid_auto/images/1603.07025_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/1903.08136/1903.08136/hybrid_auto/images/1903.08136_page0_fig0.jpg", "doc_a_figure_id": "1603.07025_fig_2", "doc_b_figure_id": "1903.08136_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does the diagonal alignment of blue points in WEAT bias effect size validation compare to the spatial segregation patterns of shapes and textures in the gray sector?", "answer": "The blue points aligned along the red dashed diagonal demonstrate high correlation between approximated and validated bias effect sizes in document removal experiments, confirming accurate bias quantification. In contrast, the gray sector's mixed distribution of blue triangles and red circles with varied textures illustrates how biased community detection methods fail to properly assign low-degree nodes, creating spatial segregation that masks opinion diversity within communities.", "query_type": "cross_comparison", "turns": ["How does the diagonal alignment of blue points in WEAT bias effect size validation compare to the spatial segregation patterns of shapes and textures in the gray sector?"], "evidence_refs": [{"doc_id": "1810.03611", "anchor": "blue data points aligned with red dashed diagonal line", "text_evidence": "The close alignment of data points along the diagonal trend line demonstrates high correlation between approximated and validated effect sizes, confirming the method's accuracy."}, {"doc_id": "1903.08136", "anchor": "gray quarter-circle sector with mixed blue triangles and red circles", "text_evidence": "many community detection approaches either fail to assign low degree (or lowly-connected) users to communities, or assign them to trivially small communities that prevent them from being included in analysis"}], "pair": {"doc_a": "1810.03611", "doc_b": "1903.08136"}, "shared_entities": ["In Figure"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1810.03611/1810.03611/hybrid_auto/images/1810.03611_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/1903.08136/1903.08136/hybrid_auto/images/1903.08136_page0_fig0.jpg", "doc_a_figure_id": "1810.03611_fig_2", "doc_b_figure_id": "1903.08136_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How does the exclusion of low-degree nodes in community detection relate to the fairness-accuracy tradeoff when constraint violations affect model performance in fair classification?", "answer": "Community detection methods fail to assign low-degree users to meaningful communities, creating trivially small clusters that exclude diverse opinions (shown by mixed shapes and textures in the gray sector). Similarly, fair classification methods face tradeoffs between test loss and constraint violations, where enforcing fairness constraints can degrade performance, as demonstrated by the convex envelopes showing increased relative loss with stricter fairness requirements across multiple oracle-model combinations.", "query_type": "cross_synthesis", "turns": ["How does the exclusion of low-degree nodes in community detection relate to the fairness-accuracy tradeoff when constraint violations affect model performance in fair classification?"], "evidence_refs": [{"doc_id": "1903.08136", "anchor": "gray quarter-circle sector with mixed blue triangles and red circles showing diverse opinions", "text_evidence": "many community detection approaches either fail to assign low degree (or lowly-connected) users to communities, or assign them to trivially small communities that prevent them from being included in analysis"}, {"doc_id": "1905.12843", "anchor": "convex envelopes showing relative test loss versus worst constraint violation for multiple methods", "text_evidence": "Relative test loss versus the worst constraint violation with respect to SP. Relative losses are computed by subtracting the smallest baseline loss from the actual loss."}], "pair": {"doc_a": "1903.08136", "doc_b": "1905.12843"}, "shared_entities": ["In Figure"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1903.08136/1903.08136/hybrid_auto/images/1903.08136_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1905.12843/1905.12843/hybrid_auto/images/1905.12843_page0_fig3.jpg", "doc_a_figure_id": "1903.08136_fig_1", "doc_b_figure_id": "1905.12843_fig_4", "qc_issues": [], "qc_pass": true}
{"query": "How does optimizing a threshold predictor using the horizontal gap between ROC curve and tangent line relate to intervening on variables in a causal graph?", "answer": "The horizontal gap optimization treats the predictor's true positive rate as a cost-minimization problem without modeling causal relationships. In contrast, intervening on a variable like A or Y in the causal graph explicitly overrides structural equations, changing the data-generating mechanism rather than just adjusting decision thresholds on fixed distributions.", "query_type": "cross_comparison", "turns": ["How does optimizing a threshold predictor using the horizontal gap between ROC curve and tangent line relate to intervening on variables in a causal graph?"], "evidence_refs": [{"doc_id": "1610.02413", "anchor": "Black arrow pointing to horizontal gap between blue ROC curve and tangent line", "text_evidence": "within each group the cost for a given true positive rate is proportional to the horizontal gap between the ROC curve and the profit-maximizing tangent line"}, {"doc_id": "1805.05859", "anchor": "Arrow from node A to node Y in causal graph diagram", "text_evidence": "a perfect intervention on a variable V_i, at value v, corresponds to overriding f_i(·) with the equation V_i = v"}], "pair": {"doc_a": "1610.02413", "doc_b": "1805.05859"}, "shared_entities": ["X1", "X2"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1610.02413/1610.02413/hybrid_auto/images/1610.02413_page0_fig3.jpg", "doc_b_image_path": "data/mineru_output/1805.05859/1805.05859/hybrid_auto/images/1805.05859_page0_fig0.jpg", "doc_a_figure_id": "1610.02413_fig_4", "doc_b_figure_id": "1805.05859_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "Can the confounding structure where C points to both A and Y explain why the Broward County detention distributions violate statistical parity despite equal means?", "answer": "The confounding structure with C as a common cause of both A and Y creates conditional dependencies that can produce unequal distributions even with equal means. In Broward County, such confounding between protected attributes and risk scores generates the observed violation of statistical parity where the blue and red distributions peak at different locations despite having equal means, demonstrating how unobserved confounders manifest as fairness violations.", "query_type": "cross_synthesis", "turns": ["Can the confounding structure where C points to both A and Y explain why the Broward County detention distributions violate statistical parity despite equal means?"], "evidence_refs": [{"doc_id": "1701.08230", "anchor": "Blue and red curves with different peak locations at 25% dashed line in simulated panel", "text_evidence": "simulated data drawn from two beta distributions with equal means (right). Bottom: using a single threshold which detains 30% of defendants in Broward County violates statistical parity"}, {"doc_id": "1705.10378", "anchor": "Node C at top with blue arrows pointing to both A (bottom-left) and Y (top-right)", "text_evidence": "C pointing to both A and Y indicates C is a common cause (confounder) that creates conditional dependencies, which causal models encode beyond standard Bayesian network independence structures"}], "pair": {"doc_a": "1701.08230", "doc_b": "1705.10378"}, "shared_entities": ["COMPAS"], "pair_score": 11.5, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1701.08230/1701.08230/hybrid_auto/images/1701.08230_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/1705.10378/1705.10378/hybrid_auto/images/1705.10378_page0_fig0.jpg", "doc_a_figure_id": "1701.08230_fig_2", "doc_b_figure_id": "1705.10378_fig_1", "qc_issues": [], "qc_pass": true}
{"query": "How might uninformative nuisance variables S affecting representations X impact the shape and density of Pareto frontiers when optimizing accuracy-fairness trade-offs across different gamma values?", "answer": "Uninformative nuisance variables S that directly affect observed data X independently of informative latent factors Z can introduce noise that degrades both accuracy and fairness metrics. This noise would likely cause the Pareto-optimal trajectories for each gamma parameter to become more dispersed and less smooth, as the color-coded curves show varying error-unfairness trade-offs that could be further scattered by uninformative dimensions unrelated to the task.", "query_type": "cross_synthesis", "turns": ["How might uninformative nuisance variables S affecting representations X impact the shape and density of Pareto frontiers when optimizing accuracy-fairness trade-offs across different gamma values?"], "evidence_refs": [{"doc_id": "1511.00830", "anchor": "Direct arrow from node S to node X, bypassing node Z", "text_evidence": "Uninformative dimensions are often called \"noise\" or \"nuisance variables\" while informative dimensions are usually called latent or hidden factors of variation."}, {"doc_id": "1711.05144", "anchor": "Multiple distinct colored curves (blue, red, green, purple, orange) showing different Pareto-optimal trajectories", "text_evidence": "Pareto-optimal error-unfairness values, color coded by varying values of the input parameter γ"}], "pair": {"doc_a": "1511.00830", "doc_b": "1711.05144"}, "shared_entities": ["accuracy"], "pair_score": 11.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1511.00830/1511.00830/hybrid_auto/images/1511.00830_page0_fig0.jpg", "doc_b_image_path": "data/mineru_output/1711.05144/1711.05144/hybrid_auto/images/1711.05144_page0_fig2.jpg", "doc_a_figure_id": "1511.00830_fig_1", "doc_b_figure_id": "1711.05144_fig_3", "qc_issues": [], "qc_pass": true}
{"query": "How does the accuracy loss from removing disparate mistreatment on both FPR and FNR compare to the error-fairness tradeoff shown by the MARGINAL algorithm?", "answer": "The fair constrained classifier removing disparate mistreatment on both FPR and FNR causes accuracy to drop from 0.80 to 0.77, representing a 3.75% decrease. Similarly, the MARGINAL algorithm demonstrates a continuous error-fairness tradeoff where reducing marginal fairness violation from 0.25 to 0 increases error from approximately 0.16 to 0.23, showing both approaches sacrifice accuracy to achieve fairness constraints.", "query_type": "cross_comparison", "turns": ["How does the accuracy loss from removing disparate mistreatment on both FPR and FNR compare to the error-fairness tradeoff shown by the MARGINAL algorithm?"], "evidence_refs": [{"doc_id": "1610.08452", "anchor": "dashed blue line with Acc=0.77 compared to solid cyan line with Acc=0.80", "text_evidence": "Removing disparate mistreatment on both at the same time causes a larger drop in accuracy"}, {"doc_id": "1808.08166", "anchor": "blue points forming downward curve from error ~0.16 at fairness ~0.25 to error ~0.23 at fairness ~0", "text_evidence": "The error and marginal fairness violation for the MARGINAL algorithm across all four data sets"}], "pair": {"doc_a": "1610.08452", "doc_b": "1808.08166"}, "shared_entities": ["Fairness", "accuracy"], "pair_score": 11.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1610.08452/1610.08452/hybrid_auto/images/1610.08452_page0_fig8.jpg", "doc_b_image_path": "data/mineru_output/1808.08166/1808.08166/hybrid_auto/images/1808.08166_page0_fig10.jpg", "doc_a_figure_id": "1610.08452_fig_9", "doc_b_figure_id": "1808.08166_fig_11", "qc_issues": [], "qc_pass": true}
{"query": "Does MNIST style-conditioned generation using digit label as covariate achieve comparable disentanglement accuracy to FFVAE's multi-attribute approach on Celeb-A for fairness-aware classification tasks?", "answer": "MNIST digit-label conditioning successfully disentangles style from class by pushing non-class information into latent space, enabling generation of all digits with consistent style. FFVAE's structured latent code using multiple sensitive attributes (Chubby, Eyeglasses, Male) achieves higher accuracy (~0.78) than X-VAE across fairness constraints, demonstrating superior disentanglement for subgroup fair classification on Celeb-A.", "query_type": "cross_comparison", "turns": ["Does MNIST style-conditioned generation using digit label as covariate achieve comparable disentanglement accuracy to FFVAE's multi-attribute approach on Celeb-A for fairness-aware classification tasks?"], "evidence_refs": [{"doc_id": "1805.09458", "anchor": "Top row showing real digit 9 generating sequence 0123456789 with preserved style", "text_evidence": "We use the digit label as the covariate class c, which pushes all non-class stylistic information into the latent space while attempting to remove information about the exact digit being written."}, {"doc_id": "1906.02589", "anchor": "Solid blue TEXAS line maintaining accuracy ~0.78 above orange X-VAE across Δ_CP values 0.00-0.40", "text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes"}], "pair": {"doc_a": "1805.09458", "doc_b": "1906.02589"}, "shared_entities": ["VAE", "accuracy"], "pair_score": 11.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1805.09458/1805.09458/hybrid_auto/images/1805.09458_page0_fig4.jpg", "doc_b_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg", "doc_a_figure_id": "1805.09458_fig_5", "doc_b_figure_id": "1906.02589_fig_29", "qc_issues": [], "qc_pass": true}
{"query": "How does the accuracy retention at disparate impact 0.8 for random forest optimized pre-processing compare to FFVAE's accuracy at Δ_CP=0.20 when balancing fairness constraints?", "answer": "Random forest with optimized pre-processing maintains approximately 0.73-0.75 balanced accuracy at disparate impact ~0.8 (top panel), while FFVAE sustains roughly 0.775 accuracy at Δ_CP=0.20. Both methods demonstrate that structured fairness interventions—whether through pre-processing bias mitigation or disentangled latent codes with multiple sensitive attributes—can preserve high accuracy while enforcing moderate fairness constraints, though FFVAE shows slightly better accuracy retention.", "query_type": "cross_comparison", "turns": ["How does the accuracy retention at disparate impact 0.8 for random forest optimized pre-processing compare to FFVAE's accuracy at Δ_CP=0.20 when balancing fairness constraints?"], "evidence_refs": [{"doc_id": "1810.01943", "anchor": "green circles (RF,Optimized pre-processing) at disparate impact ~0.8 in top panel showing balanced accuracy ~0.73-0.75", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0. The circles indicate the mean value"}, {"doc_id": "1906.02589", "anchor": "solid blue FFVAE line at Δ_CP=0.20 maintaining accuracy ~0.775", "text_evidence": "we discussed how disentangled representation learning aligns with the goals of subgroup fair machine learning, and presented a method for learning a structured latent code using multiple sensitive attributes"}], "pair": {"doc_a": "1810.01943", "doc_b": "1906.02589"}, "shared_entities": ["Fairness", "accuracy", "parity"], "pair_score": 11.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_b_image_path": "data/mineru_output/1906.02589/1906.02589/hybrid_auto/images/1906.02589_page0_fig28.jpg", "doc_a_figure_id": "1810.01943_fig_10", "doc_b_figure_id": "1906.02589_fig_29", "qc_issues": [], "qc_pass": true}
{"query": "Can optimized pre-processing methods achieving disparate impact ~0.8 still identify causal effects when unobserved confounders create bidirected links between protected attributes and outcomes?", "answer": "Optimized pre-processing methods shown by green circles at disparate impact ~0.8 improve fairness metrics toward the ideal value of 1. However, when unobserved confounders exist (represented by red bidirected links in ADMGs), causal effects along paths like A→Y cannot be identified using only observed variables, potentially limiting the ability of pre-processing to address true causal fairness.", "query_type": "cross_synthesis", "turns": ["Can optimized pre-processing methods achieving disparate impact ~0.8 still identify causal effects when unobserved confounders create bidirected links between protected attributes and outcomes?"], "evidence_refs": [{"doc_id": "1802.08139", "anchor": "Red bidirected edge between A and Y in ADMG subfigure (b), and gray node C representing unobserved confounder", "text_evidence": "An ADMG is a causal graph containing two kinds of links, directed links (either green or black depending on whether we are interested in the corresponding causal path), and red bidirected links, indicating the presence of an unobserved common cause. The causal effect along the green path A → Y cannot be identified by only using observed variables."}, {"doc_id": "1810.01943", "anchor": "Green circles (RF,Optimized pre-processing) at disparate impact ~0.8 in top panel", "text_evidence": "The ideal fair value of disparate impact is 1, whereas for all other metrics it is 0. The circles indicate the mean value and Four different fairness metrics are shown."}], "pair": {"doc_a": "1802.08139", "doc_b": "1810.01943"}, "shared_entities": ["German Credit"], "pair_score": 11.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1802.08139/1802.08139/hybrid_auto/images/1802.08139_page0_fig16.jpg", "doc_b_image_path": "data/mineru_output/1810.01943/1810.01943/hybrid_auto/images/1810.01943_page0_fig9.jpg", "doc_a_figure_id": "1802.08139_fig_17", "doc_b_figure_id": "1810.01943_fig_10", "qc_issues": [], "qc_pass": true}
{"query": "How does the two orders of magnitude gap between Reddit's cumulative subreddits and users relate to the proportional allocation principle where groups N and M receive equal shares?", "answer": "Reddit's structure shows many users distributed across fewer subreddits (10^5 subreddits serving 10^7 users by 2014), contrasting with proportional fairness where equal-sized groups receive equal shares of resources. While proportional allocation entitles groups to proportional shares of centers, Reddit demonstrates a many-to-few mapping where numerous users concentrate in relatively fewer community spaces rather than receiving proportional subreddit representation.", "query_type": "cross_contradiction", "turns": ["How does the two orders of magnitude gap between Reddit's cumulative subreddits and users relate to the proportional allocation principle where groups N and M receive equal shares?"], "evidence_refs": [{"doc_id": "1603.07025", "anchor": "dashed teal line at 10^5 and solid purple line at 10^7 by 2014", "text_evidence": "An active user or subreddit is one that had at least one post (comment or submission) in the time bin we used—here, discretized by month"}, {"doc_id": "1905.03674", "anchor": "two red centers positioned symmetrically for equal groups N and M", "text_evidence": "Proportionality has many advantages as a notion of fairness in clustering, beyond the intuitive appeal of groups being entitled to a proportional share of centers"}], "pair": {"doc_a": "1603.07025", "doc_b": "1905.03674"}, "shared_entities": ["In Figure"], "pair_score": 11.0, "images_sent": 2, "doc_a_image_path": "data/mineru_output/1603.07025/1603.07025/hybrid_auto/images/1603.07025_page0_fig1.jpg", "doc_b_image_path": "data/mineru_output/1905.03674/1905.03674/hybrid_auto/images/1905.03674_page0_fig0.jpg", "doc_a_figure_id": "1603.07025_fig_2", "doc_b_figure_id": "1905.03674_fig_1", "qc_issues": [], "qc_pass": true}
