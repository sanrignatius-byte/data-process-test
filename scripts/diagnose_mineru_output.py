#!/usr/bin/env python3
"""
MinerU Output Diagnostic Tool

æ£€æŸ¥MinerUè§£æè¾“å‡ºçš„å®é™…ç»“æ„ï¼Œå¸®åŠ©è¯Šæ–­è§£æé—®é¢˜ã€‚

Usage:
    python scripts/diagnose_mineru_output.py /path/to/mineru_output
    python scripts/diagnose_mineru_output.py /path/to/mineru_output --doc-id paper_001
"""

import os
import sys
import json
import argparse
from pathlib import Path
from collections import defaultdict


def scan_directory_structure(output_dir: Path, max_depth: int = 4) -> dict:
    """é€’å½’æ‰«æç›®å½•ç»“æ„"""
    structure = {
        "path": str(output_dir),
        "files": [],
        "dirs": [],
        "file_count": 0,
        "dir_count": 0
    }

    if not output_dir.exists():
        structure["error"] = "ç›®å½•ä¸å­˜åœ¨"
        return structure

    for item in sorted(output_dir.iterdir()):
        if item.is_file():
            file_info = {
                "name": item.name,
                "size": item.stat().st_size,
                "ext": item.suffix
            }
            structure["files"].append(file_info)
            structure["file_count"] += 1
        elif item.is_dir() and max_depth > 0:
            sub_structure = scan_directory_structure(item, max_depth - 1)
            structure["dirs"].append(sub_structure)
            structure["dir_count"] += 1

    return structure


def find_all_files(output_dir: Path, pattern: str = "*") -> list:
    """æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶"""
    return list(output_dir.rglob(pattern))


def analyze_mineru_output(output_dir: Path) -> dict:
    """åˆ†æMinerUè¾“å‡ºç›®å½•"""
    analysis = {
        "output_dir": str(output_dir),
        "exists": output_dir.exists(),
        "documents": [],
        "summary": {
            "total_docs": 0,
            "successful_docs": 0,
            "failed_docs": 0,
            "file_types_found": defaultdict(int)
        }
    }

    if not output_dir.exists():
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {output_dir}")
        return analysis

    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–‡æ¡£è¾“å‡ºç›®å½•
    doc_dirs = []

    # æ–¹å¼1: ç›´æ¥å­ç›®å½•
    for item in output_dir.iterdir():
        if item.is_dir() and not item.name.startswith('.'):
            doc_dirs.append(item)

    # å¦‚æœæ²¡æœ‰å­ç›®å½•ï¼Œå¯èƒ½è¾“å‡ºç›´æ¥åœ¨å½“å‰ç›®å½•
    if not doc_dirs:
        doc_dirs = [output_dir]

    print(f"\nğŸ“ æ‰«æç›®å½•: {output_dir}")
    print(f"   æ‰¾åˆ° {len(doc_dirs)} ä¸ªæ½œåœ¨æ–‡æ¡£ç›®å½•\n")

    for doc_dir in doc_dirs:
        doc_analysis = analyze_single_document(doc_dir)
        analysis["documents"].append(doc_analysis)

        if doc_analysis["has_content"]:
            analysis["summary"]["successful_docs"] += 1
        else:
            analysis["summary"]["failed_docs"] += 1
        analysis["summary"]["total_docs"] += 1

        for ext, count in doc_analysis["file_types"].items():
            analysis["summary"]["file_types_found"][ext] += count

    return analysis


def analyze_single_document(doc_dir: Path) -> dict:
    """åˆ†æå•ä¸ªæ–‡æ¡£çš„è¾“å‡º"""
    doc_analysis = {
        "doc_dir": str(doc_dir),
        "doc_name": doc_dir.name,
        "has_content": False,
        "structure": {},
        "file_types": defaultdict(int),
        "important_files": {
            "markdown": [],
            "json": [],
            "images": [],
            "formula": []
        },
        "issues": []
    }

    # æ£€æŸ¥ auto å­ç›®å½• (MinerUå¸¸è§ç»“æ„)
    auto_dir = doc_dir / "auto"
    content_dir = auto_dir if auto_dir.exists() else doc_dir

    # æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶
    all_files = list(doc_dir.rglob("*"))

    for f in all_files:
        if f.is_file():
            ext = f.suffix.lower()
            doc_analysis["file_types"][ext] += 1

            # åˆ†ç±»é‡è¦æ–‡ä»¶
            if ext == ".md":
                doc_analysis["important_files"]["markdown"].append(str(f.relative_to(doc_dir)))
            elif ext == ".json":
                doc_analysis["important_files"]["json"].append(str(f.relative_to(doc_dir)))
            elif ext in [".png", ".jpg", ".jpeg", ".gif"]:
                doc_analysis["important_files"]["images"].append(str(f.relative_to(doc_dir)))

    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    key_files = {
        # MinerUæ–°ç‰ˆè¾“å‡ºæ ¼å¼
        "structure.json": ["structure.json", "auto/structure.json"],
        "formula.md": ["formula.md", "auto/formula.md"],
        # MinerUæ—§ç‰ˆè¾“å‡ºæ ¼å¼
        "content_list.json": ["content_list.json", "auto/content_list.json"],
        "middle.json": ["middle.json", "auto/middle.json"],
        # é€šç”¨
        "content.md": ["content.md", "auto/content.md", f"{doc_dir.name}.md", f"auto/{doc_dir.name}.md"],
    }

    doc_analysis["structure"]["key_files"] = {}
    for key_name, possible_paths in key_files.items():
        found = False
        for p in possible_paths:
            full_path = doc_dir / p
            if full_path.exists():
                doc_analysis["structure"]["key_files"][key_name] = str(p)
                found = True
                break
        if not found:
            doc_analysis["structure"]["key_files"][key_name] = None

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹
    has_md = len(doc_analysis["important_files"]["markdown"]) > 0
    has_json = len(doc_analysis["important_files"]["json"]) > 0
    has_images = len(doc_analysis["important_files"]["images"]) > 0

    doc_analysis["has_content"] = has_md or has_json

    # è®°å½•é—®é¢˜
    if not has_md:
        doc_analysis["issues"].append("ç¼ºå°‘Markdownæ–‡ä»¶")
    if not has_json:
        doc_analysis["issues"].append("ç¼ºå°‘JSONç»“æ„æ–‡ä»¶")
    if not has_images:
        doc_analysis["issues"].append("æ²¡æœ‰æå–åˆ°å›¾ç‰‡")

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–°ç‰ˆæ ¼å¼
    if doc_analysis["structure"]["key_files"].get("structure.json"):
        doc_analysis["mineru_version"] = "æ–°ç‰ˆ (structure.json)"
    elif doc_analysis["structure"]["key_files"].get("content_list.json"):
        doc_analysis["mineru_version"] = "æ—§ç‰ˆ (content_list.json)"
    else:
        doc_analysis["mineru_version"] = "æœªçŸ¥"

    return doc_analysis


def inspect_json_file(json_path: Path) -> dict:
    """æ·±å…¥æ£€æŸ¥JSONæ–‡ä»¶ç»“æ„"""
    inspection = {
        "path": str(json_path),
        "size": json_path.stat().st_size,
        "readable": False,
        "structure": None,
        "sample": None
    }

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        inspection["readable"] = True

        if isinstance(data, dict):
            inspection["structure"] = {k: type(v).__name__ for k in list(data.keys())[:20]}
            inspection["top_level_keys"] = list(data.keys())
        elif isinstance(data, list):
            inspection["structure"] = f"list with {len(data)} items"
            if data:
                if isinstance(data[0], dict):
                    inspection["item_keys"] = list(data[0].keys())[:10]
                inspection["sample"] = str(data[0])[:500]
    except Exception as e:
        inspection["error"] = str(e)

    return inspection


def print_analysis(analysis: dict):
    """æ‰“å°åˆ†æç»“æœ"""
    print("\n" + "="*70)
    print("ğŸ“Š MinerU è¾“å‡ºåˆ†ææŠ¥å‘Š")
    print("="*70)

    summary = analysis["summary"]
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {analysis['output_dir']}")
    print(f"ğŸ“„ æ€»æ–‡æ¡£æ•°: {summary['total_docs']}")
    print(f"âœ… æˆåŠŸè§£æ: {summary['successful_docs']}")
    print(f"âŒ è§£æå¤±è´¥: {summary['failed_docs']}")

    print(f"\nğŸ“‘ æ–‡ä»¶ç±»å‹ç»Ÿè®¡:")
    for ext, count in sorted(summary['file_types_found'].items(), key=lambda x: -x[1]):
        print(f"   {ext or '(æ— æ‰©å±•å)'}: {count}")

    # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯
    print(f"\nğŸ“‹ æ–‡æ¡£è¯¦æƒ… (æ˜¾ç¤ºå‰5ä¸ª):")
    print("-"*70)

    for doc in analysis["documents"][:5]:
        status = "âœ…" if doc["has_content"] else "âŒ"
        print(f"\n{status} {doc['doc_name']}")
        print(f"   ç‰ˆæœ¬: {doc.get('mineru_version', 'æœªçŸ¥')}")
        print(f"   Markdownæ–‡ä»¶: {len(doc['important_files']['markdown'])}")
        print(f"   JSONæ–‡ä»¶: {len(doc['important_files']['json'])}")
        print(f"   å›¾ç‰‡: {len(doc['important_files']['images'])}")

        if doc["structure"]["key_files"]:
            print(f"   å…³é”®æ–‡ä»¶:")
            for key, path in doc["structure"]["key_files"].items():
                if path:
                    print(f"      âœ“ {key}: {path}")
                else:
                    print(f"      âœ— {key}: æœªæ‰¾åˆ°")

        if doc["issues"]:
            print(f"   âš ï¸  é—®é¢˜: {', '.join(doc['issues'])}")

    if len(analysis["documents"]) > 5:
        print(f"\n... è¿˜æœ‰ {len(analysis['documents']) - 5} ä¸ªæ–‡æ¡£æœªæ˜¾ç¤º")


def suggest_fixes(analysis: dict):
    """æ ¹æ®åˆ†æç»“æœå»ºè®®ä¿®å¤æ–¹æ¡ˆ"""
    print("\n" + "="*70)
    print("ğŸ’¡ å»ºè®®ä¿®å¤æ–¹æ¡ˆ")
    print("="*70)

    issues = []

    # æ£€æŸ¥æ˜¯å¦æœ‰structure.jsonä½†ä»£ç ä¸æ”¯æŒ
    has_new_format = False
    has_old_format = False

    for doc in analysis["documents"]:
        if doc["structure"]["key_files"].get("structure.json"):
            has_new_format = True
        if doc["structure"]["key_files"].get("content_list.json"):
            has_old_format = True

    if has_new_format and not has_old_format:
        issues.append({
            "é—®é¢˜": "MinerUä½¿ç”¨æ–°ç‰ˆè¾“å‡ºæ ¼å¼ (structure.json)ï¼Œä½†ä»£ç åªæ”¯æŒæ—§ç‰ˆ",
            "å»ºè®®": "éœ€è¦æ›´æ–° mineru_parser.py æ¥æ”¯æŒ structure.json æ ¼å¼",
            "priority": "é«˜"
        })

    if analysis["summary"]["failed_docs"] > 0:
        issues.append({
            "é—®é¢˜": f"æœ‰ {analysis['summary']['failed_docs']} ä¸ªæ–‡æ¡£è§£æå¤±è´¥",
            "å»ºè®®": "æ£€æŸ¥MinerUæ—¥å¿—ï¼Œå¯èƒ½æ˜¯PDFæŸåæˆ–GPUå†…å­˜ä¸è¶³",
            "priority": "é«˜"
        })

    # æ£€æŸ¥å›¾ç‰‡
    total_images = analysis["summary"]["file_types_found"].get(".png", 0) + \
                   analysis["summary"]["file_types_found"].get(".jpg", 0)
    if total_images == 0:
        issues.append({
            "é—®é¢˜": "æ²¡æœ‰æå–åˆ°ä»»ä½•å›¾ç‰‡",
            "å»ºè®®": "æ£€æŸ¥MinerUé…ç½®ï¼Œç¡®ä¿å¯ç”¨äº†å›¾ç‰‡æå–",
            "priority": "ä¸­"
        })

    if not issues:
        print("\nâœ… æ²¡æœ‰å‘ç°æ˜æ˜¾é—®é¢˜!")
    else:
        for i, issue in enumerate(issues, 1):
            print(f"\n{i}. [{issue['priority']}ä¼˜å…ˆçº§] {issue['é—®é¢˜']}")
            print(f"   ğŸ’¡ {issue['å»ºè®®']}")

    return issues


def main():
    parser = argparse.ArgumentParser(description="MinerUè¾“å‡ºè¯Šæ–­å·¥å…·")
    parser.add_argument("output_dir", help="MinerUè¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--doc-id", help="åªæ£€æŸ¥ç‰¹å®šæ–‡æ¡£")
    parser.add_argument("--inspect-json", help="æ·±å…¥æ£€æŸ¥ç‰¹å®šJSONæ–‡ä»¶")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    output_dir = Path(args.output_dir)

    if args.inspect_json:
        json_path = Path(args.inspect_json)
        if not json_path.exists():
            json_path = output_dir / args.inspect_json

        if json_path.exists():
            inspection = inspect_json_file(json_path)
            print(f"\nğŸ“‹ JSONæ–‡ä»¶æ£€æŸ¥: {inspection['path']}")
            print(f"   å¤§å°: {inspection['size']} bytes")
            print(f"   å¯è¯»: {inspection['readable']}")
            if inspection.get("top_level_keys"):
                print(f"   é¡¶å±‚é”®: {inspection['top_level_keys']}")
            if inspection.get("structure"):
                print(f"   ç»“æ„: {inspection['structure']}")
            if inspection.get("item_keys"):
                print(f"   é¡¹ç›®é”®: {inspection['item_keys']}")
            if inspection.get("sample"):
                print(f"   ç¤ºä¾‹: {inspection['sample'][:200]}...")
        else:
            print(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return

    if args.doc_id:
        doc_path = output_dir / args.doc_id
        if not doc_path.exists():
            # å°è¯•æŸ¥æ‰¾
            matches = list(output_dir.glob(f"*{args.doc_id}*"))
            if matches:
                doc_path = matches[0]

        if doc_path.exists():
            doc_analysis = analyze_single_document(doc_path)
            print(f"\nğŸ“„ æ–‡æ¡£åˆ†æ: {args.doc_id}")
            print(json.dumps(doc_analysis, indent=2, ensure_ascii=False, default=str))
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡æ¡£: {args.doc_id}")
        return

    # å®Œæ•´åˆ†æ
    analysis = analyze_mineru_output(output_dir)
    print_analysis(analysis)
    suggest_fixes(analysis)

    # ä¿å­˜åˆ†æç»“æœ
    report_path = output_dir / "diagnosis_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False, default=str)
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


if __name__ == "__main__":
    main()
